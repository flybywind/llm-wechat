{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "from secret import AK_SK\n",
    "keys = AK_SK('../qianfan.keys')\n",
    "os.environ[\"QIANFAN_ACCESS_KEY\"] = keys.get_ak()\n",
    "os.environ[\"QIANFAN_SECRET_KEY\"] = keys.get_sk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from myqianfan import QianfanLLM, QianfanEmbedding\n",
    "from myqianfan import model_spec\n",
    "\n",
    "llm = QianfanLLM(model_spec=model_spec.ERNIE4_Turbo8K, temperature=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from atlassian import Confluence\n",
    "from langchain import hub\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import ConfluenceLoader\n",
    "from langchain.schema import BaseOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma(\"qianfan\", embedding_function=QianfanEmbedding(), persist_directory=\"vectorstore/qianfan.vec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第一次初始化时运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_children_pages_recursively(client, page_id: str):\n",
    "    child_pages = client.get_page_child_by_type(page_id)\n",
    "    for page in child_pages:\n",
    "        yield page\n",
    "        if \"id\" in page:\n",
    "            yield from get_children_pages_recursively(client, page[\"id\"])\n",
    "\n",
    "from getpass import getpass\n",
    "wiki_psw = getpass(\"wiki:\")\n",
    "# get all pages under some page\n",
    "confluence = Confluence(\n",
    "    url='https://wiki.fintopia.tech/',\n",
    "    username='tongxinwen@fintopia.tech',\n",
    "    password=wiki_psw)\n",
    "child_pages = [p for p in get_children_pages_recursively(confluence, \"74290517\")]\n",
    "\n",
    "loader = ConfluenceLoader(\n",
    "    url=\"https://wiki.fintopia.tech/\",\n",
    "    page_ids=[p[\"id\"] for p in child_pages],\n",
    "    username=\"tongxinwen@fintopia.tech\",\n",
    "    api_key=wiki_psw,\n",
    "    limit=10,\n",
    ")\n",
    "documents = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=100)\n",
    "splits = text_splitter.split_documents(documents)\n",
    "\n",
    "batch_size = 16\n",
    "doc_ids = []\n",
    "for i in range(0, len(splits), batch_size):\n",
    "    print(f\"Adding documents {i} to {i+batch_size}\")\n",
    "    texts = [doc.page_content for doc in splits[i:i+batch_size]]\n",
    "    metadatas = [doc.metadata for doc in splits[i:i+batch_size]]\n",
    "    doc_ids += vectorstore.add_texts(texts, metadatas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'id': '95160416', 'source': 'https://wiki.fintopia.tech/display/riskDev/2024H2', 'title': '2024H2', 'when': '2024-07-09T17:39:33.000+08:00'}, page_content='200ms KR3 模型推理框架国内外统一 【P2】 KR4 模型cache表优化，提高插入和查询效率，同时降低存储压力【P2】 建立HBase + Hive + PolarDB 3位一体的多级缓存 查询方面通过PolarDB + HBase提供高效查询，存储方面通过Hive提供长期存储功能，方面回溯各种问题 建立各级存储模块的过期策略，在PolarDB中存储原来的30%的数据，HBase存储未过期model的所有记录，hive存储最近3年的所有记录 O5 海外平台搭建 【P0】 以菲律宾、印尼为主 目标，训练全部迁移到ailab，推理迁移到新框架。'),\n",
       " Document(metadata={'id': '95160416', 'source': 'https://wiki.fintopia.tech/display/riskDev/2024H2', 'title': '2024H2', 'when': '2024-07-09T17:39:33.000+08:00'}, page_content='200ms KR3 模型推理框架国内外统一 【P2】 KR4 模型cache表优化，提高插入和查询效率，同时降低存储压力【P2】 建立HBase + Hive + PolarDB 3位一体的多级缓存 查询方面通过PolarDB + HBase提供高效查询，存储方面通过Hive提供长期存储功能，方面回溯各种问题 建立各级存储模块的过期策略，在PolarDB中存储原来的30%的数据，HBase存储未过期model的所有记录，hive存储最近3年的所有记录 O5 海外平台搭建 【P0】 以菲律宾、印尼为主 目标，训练全部迁移到ailab，推理迁移到新框架。'),\n",
       " Document(metadata={'id': '91856753', 'source': 'https://wiki.fintopia.tech/pages/viewpage.action?pageId=91856753', 'title': '7. 在AiLab中连接hive', 'when': '2024-09-03T14:48:03.000+08:00'}, page_content='因为权限管理和LDAP一样，所以用户如果想要申请某个表的权限，需要去数仓申请 https://dw-lighthouse.fintopia.tech/tools/hive-permission 另外，如果不想把自己的密码保存在ipynb中，可以使用getpass函数，如下，这样就保存在passwd这个变量里了 ！！注意 ！！ hive.read_sql 这句话会把整个表下载到本地。强烈建议先在SQL中对数据进行过滤，采样或者group。 比如如果想知道某个表的行数，我们应该这样做： py 而不是这样：否则很可能把AiLab打挂 py 向hive中导入表 py \",'),\n",
       " Document(metadata={'id': '91856753', 'source': 'https://wiki.fintopia.tech/pages/viewpage.action?pageId=91856753', 'title': '7. 在AiLab中连接hive', 'when': '2024-09-03T14:48:03.000+08:00'}, page_content='因为权限管理和LDAP一样，所以用户如果想要申请某个表的权限，需要去数仓申请 https://dw-lighthouse.fintopia.tech/tools/hive-permission 另外，如果不想把自己的密码保存在ipynb中，可以使用getpass函数，如下，这样就保存在passwd这个变量里了 ！！注意 ！！ hive.read_sql 这句话会把整个表下载到本地。强烈建议先在SQL中对数据进行过滤，采样或者group。 比如如果想知道某个表的行数，我们应该这样做： py 而不是这样：否则很可能把AiLab打挂 py 向hive中导入表 py \",')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorstore.search(\"数据库\", search_type=\"similarity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建Rag chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"human\", \"你是一个解答用户问题的assistant，可以根据从语料库中召回的context文本回答问题。请尽量保证回答的内容都可以在context中找到根据，并务必保留==>source后面的url链接。以下是context文本：{context}，问题是：{question}\"),\n",
    "            (\"assistant\", \"根据context文本，我认为答案是：\"),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for ChatPromptTemplate\n__root__\n  Expecting value: line 1 column 1 (char 0) [type=value_error.jsondecode, input_value='Human: 你是一个解...我认为答案是：', input_type=str]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.11/site-packages/pydantic/main.py:1187\u001b[0m, in \u001b[0;36mBaseModel.parse_raw\u001b[0;34m(cls, b, content_type, encoding, proto, allow_pickle)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1187\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43mparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_str_bytes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1189\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproto\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproto\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontent_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.11/site-packages/pydantic/deprecated/parse.py:49\u001b[0m, in \u001b[0;36mload_str_bytes\u001b[0;34m(b, content_type, encoding, proto, allow_pickle, json_loads)\u001b[0m\n\u001b[1;32m     48\u001b[0m         b \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mdecode(encoding)\n\u001b[0;32m---> 49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson_loads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m proto \u001b[38;5;241m==\u001b[39m Protocol\u001b[38;5;241m.\u001b[39mpickle:\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.11/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.11/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03mcontaining a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.11/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mprompt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconversation_history\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.11/site-packages/pydantic/main.py:1214\u001b[0m, in \u001b[0;36mBaseModel.parse_raw\u001b[0;34m(cls, b, content_type, encoding, proto, allow_pickle)\u001b[0m\n\u001b[1;32m   1207\u001b[0m     \u001b[38;5;66;03m# ctx is missing here, but since we've added `input` to the error, we're not pretending it's the same\u001b[39;00m\n\u001b[1;32m   1208\u001b[0m     error: pydantic_core\u001b[38;5;241m.\u001b[39mInitErrorDetails \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1209\u001b[0m         \u001b[38;5;66;03m# The type: ignore on the next line is to ignore the requirement of LiteralString\u001b[39;00m\n\u001b[1;32m   1210\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m: pydantic_core\u001b[38;5;241m.\u001b[39mPydanticCustomError(type_str, \u001b[38;5;28mstr\u001b[39m(exc)),  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   1211\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloc\u001b[39m\u001b[38;5;124m'\u001b[39m: (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__root__\u001b[39m\u001b[38;5;124m'\u001b[39m,),\n\u001b[1;32m   1212\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m: b,\n\u001b[1;32m   1213\u001b[0m     }\n\u001b[0;32m-> 1214\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m pydantic_core\u001b[38;5;241m.\u001b[39mValidationError\u001b[38;5;241m.\u001b[39mfrom_exception_data(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, [error])\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_validate(obj)\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for ChatPromptTemplate\n__root__\n  Expecting value: line 1 column 1 (char 0) [type=value_error.jsondecode, input_value='Human: 你是一个解...我认为答案是：', input_type=str]"
     ]
    }
   ],
   "source": [
    "prompt.parse_raw(llm.conversation_history[-2]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(f\"{d.page_content}\\n==>source: {d.metadata['source']}\" for d in docs) \n",
    "\n",
    "def retrieve_from_conversation_history(llm, retriever):\n",
    "    question_history = [c['content'] for c in llm.get_conversation_history() if c['role'] == 'user']\n",
    "    return vectorstore.search(conversation_history, search_type=\"similarity\")\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'公共资源池和私有资源池的区别主要在于付费方式、资源使用优先级、创建和启动实例的速度以及资源的归属。\\n\\n1. 付费方式：公共资源池是后付费的，根据小时数计费，不用不计费。而私有资源池是预付费的，即钱已经花出去了，不用就浪费了。==>source: [https://wiki.fintopia.tech/pages/viewpage.action?pageId=80187151](https://wiki.fintopia.tech/pages/viewpage.action?pageId=80187151)\\n2. 资源使用优先级：当用户提交任务时，系统会优先选择私有资源池的资源，如果私有资源池没有资源了，才会选择公共资源池。==>source: [https://wiki.fintopia.tech/pages/viewpage.action?pageId=106844570](https://wiki.fintopia.tech/pages/viewpage.action?pageId=106844570)\\n3. 创建和启动实例的速度：私有资源池的特点是创建和启动实例快，但如果用的人多了可能没资源。而公共资源池的特点是创建和启动实例比较慢。==>source: [https://wiki.fintopia.tech/pages/viewpage.action?pageId=80187151](https://wiki.fintopia.tech/pages/viewpage.action?pageId=80187151)\\n4. 资源的归属：公共资源池属于阿里云的大池子，而私有资源池是我们自己买的一个小池子。==>source: [https://wiki.fintopia.tech/pages/viewpage.action?pageId=80187151](https://wiki.fintopia.tech/pages/viewpage.action?pageId=80187151)'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"公共资源池和私有资源池的区别\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'进行分布式LightGBM模型训练，可以利用Ray框架来实现。Ray是一款支持LightGBM等多种模型框架的分布式训练机器学习框架。它的LightGBM分布式训练方法本身是利用了LightGBM自身的分布式训练功能，Ray只是为其提供了一套多机的分布式计算框架。关于LightGBM的分布式训练原理，可以参考其官方文档：https://lightgbm.readthedocs.io/en/latest/Features.html#optimization-in-distributed-learning。\\n\\n==>source: https://wiki.fintopia.tech/pages/viewpage.action?pageId=97186155'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"如何进行分布式LightGBM模型训练\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'根据提供的context文本，进行分布式LightGBM模型训练或相关操作需要具备以下前提条件：\\n\\n1. 需要有一个开关结合待替换模型id列表配置和服务名称的配置。这是在构建过程中判断是否需要使用复制的模型id来查询特征依赖进行构建的基础。\\n==>source: https://wiki.fintopia.tech/pages/viewpage.action?pageId=84512081\\n\\n2. 在特定的环境（mirror或prod）中，需要满足特定的条件，如model-mirror环境中模型被复制了一个新modelInfo，或者在prod环境中useNewFeatureListSwitch开启且待替换模型id列表中包含当前模型id。\\n==>source: https://wiki.fintopia.tech/pages/viewpage.action?pageId=84512081\\n\\n3. 对于文件填写要求，需要上传特定格式的txt文件，文件中每行代表一个特征，特征之间以\\\\t分隔，且文件从第二行开始读取。这是进行模型训练或部署时，对输入数据的基本要求。\\n==>source: https://wiki.fintopia.tech/pages/viewpage.action?pageId=85647676'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"需要具备哪些前提条件\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'user',\n",
       " 'content': 'Human: 你是一个解答用户问题的assistant，可以根据从语料库中召回的context文本回答问题。请尽量保证回答的内容都可以在context中找到根据，并务必保留==>source后面的url链接。以下是context文本：增加一个开关结合待替换模型id列表配置和服务名称,在构建时如果符合条件,则将去查当前模型复制出来的模型id,使用复制的模型id查询特征依赖进行构建 具体判断如下 if （model-mirror && 通过model_id查询到它复制了一个新modelInfo) || (useNewFeatureListSwitch &&\\xa0toReplaceModelList.contains(modelId) )： // 查询复制的新model info，并用它构建元数据 else: // 跟原来一样 if 条件的第一部分是在mirror环境中生效，第二部分在prod环境生效。 配置 样例 说明\\n==>source: https://wiki.fintopia.tech/pages/viewpage.action?pageId=84512081\\n\\n增加一个开关结合待替换模型id列表配置和服务名称,在构建时如果符合条件,则将去查当前模型复制出来的模型id,使用复制的模型id查询特征依赖进行构建 具体判断如下 if （model-mirror && 通过model_id查询到它复制了一个新modelInfo) || (useNewFeatureListSwitch &&\\xa0toReplaceModelList.contains(modelId) )： // 查询复制的新model info，并用它构建元数据 else: // 跟原来一样 if 条件的第一部分是在mirror环境中生效，第二部分在prod环境生效。 配置 样例 说明\\n==>source: https://wiki.fintopia.tech/pages/viewpage.action?pageId=84512081\\n\\n2、文件填写要求： （1）上传txt文件，一行一个特征，以\\\\t分隔。无需分箱分箱规则不填写 （2）文件从第二行开始读取 （3）示例：索引 特征名称 特征场景 默认值 是否有flag特征 分箱规则 示例：0 nifa_sharedqueryfeatureloanamount C NaN TRUE [{\"bin\":\"(0,1]\",\"score\":0.1},{\"bin\":\"(1 2]\",\"score\"0.2},{\"bin\":\"(2 3]\",\"score\"0.3}] CV模型组部署 只描述与单模型操作差异点 1、基本信息 （1）英文名称、中文名称、描述、场景、框架、类型、空值特征分数与上述单模型一致\\n==>source: https://wiki.fintopia.tech/pages/viewpage.action?pageId=85647676\\n\\n2、文件填写要求： （1）上传txt文件，一行一个特征，以\\\\t分隔。无需分箱分箱规则不填写 （2）文件从第二行开始读取 （3）示例：索引 特征名称 特征场景 默认值 是否有flag特征 分箱规则 示例：0 nifa_sharedqueryfeatureloanamount C NaN TRUE [{\"bin\":\"(0,1]\",\"score\":0.1},{\"bin\":\"(1 2]\",\"score\"0.2},{\"bin\":\"(2 3]\",\"score\"0.3}] CV模型组部署 只描述与单模型操作差异点 1、基本信息 （1）英文名称、中文名称、描述、场景、框架、类型、空值特征分数与上述单模型一致\\n==>source: https://wiki.fintopia.tech/pages/viewpage.action?pageId=85647676，问题是：需要具备哪些前提条件\\nAI: 根据context文本，我认为答案是：'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.conversation_history[-2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
