{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "from secret import AK_SK\n",
    "keys = AK_SK('../qianfan.keys')\n",
    "os.environ[\"QIANFAN_ACCESS_KEY\"] = keys.get_ak()\n",
    "os.environ[\"QIANFAN_SECRET_KEY\"] = keys.get_sk()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING][2024-10-14 22:37:10.648] redis_rate_limiter.py:21 [t:8703163072]: no redis installed, RedisRateLimiter unavailable\n",
      "[WARNING][2024-10-14 22:37:11.119] base.py:916 [t:8703163072]: This key `disable_search` does not seem to be a parameter that the model `ERNIE-Tiny-8K` will accept\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "世界上最大的动物是鲸鱼。鲸鱼是一种大型海洋哺乳动物，属于鲸目。它们生活在海洋中，体型巨大，是已知动物中最大的种类之一。\n"
     ]
    }
   ],
   "source": [
    "from myqianfan import QianfanLLM\n",
    "from myqianfan import model_spec\n",
    "\n",
    "llm = QianfanLLM(model_spec=model_spec.Tiny8K, temperature=0.3)\n",
    "\n",
    "print(llm.invoke(\"你好, 世界上最大的动物是什么？\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Load, chunk and index the contents of the blog.\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://aitutor.liduos.com/01-llm/01-1.html\",\n",
    "     \"https://aitutor.liduos.com/01-llm/01-2.html\",\n",
    "     \"https://aitutor.liduos.com/01-llm/01-3.html\"),\n",
    "    # bs_kwargs=dict(\n",
    "    #     parse_only=bs4.SoupStrainer(\n",
    "    #         class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "    #     )\n",
    "    # ),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=100)\n",
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'https://aitutor.liduos.com/01-llm/01-3.html', 'title': 'OpenAI 文档解读 · LLM 应用开发实践笔记', 'description': '', 'language': 'zh-hans'}, page_content='OpenAI 文档解读 · LLM 应用开发实践笔记\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n作者：莫尔索\\n\\n\\n\\n\\n            \\n                    \\n                    前言\\n            \\n                \\n\\n\\n\\n            \\n                    \\n                    关注《莫尔索随笔》')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc3 = [d for d in splits if d.metadata['source'] == \"https://aitutor.liduos.com/01-llm/01-3.html\"]\n",
    "doc3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 0: OpenAI 文档解读 · LLM 应用开发实践笔记\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "作者：莫尔索\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    前言\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    关注《莫尔索随笔》\n",
      "Chunk 1: 作者：莫尔索\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    前言\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    关注《莫尔索随笔》\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    大语言模型概述\n",
      "Chunk 2: 关注《莫尔索随笔》\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    大语言模型概述\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    大语言模型概况\n",
      "Chunk 3: 大语言模型概述\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    大语言模型概况\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    你好, ChatGPT\n",
      "Chunk 4: 大语言模型概况\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    你好, ChatGPT\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    OpenAI 文档解读\n",
      "Chunk 5: 你好, ChatGPT\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    OpenAI 文档解读\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    动手实现聊天机器人\n",
      "Chunk 6: 动手实现聊天机器人\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    基于 OpenAI API 搭建一个端到端问答系统\n",
      "Chunk 7: 基于 OpenAI API 搭建一个端到端问答系统\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    LLM 安全专题\n",
      "Chunk 8: LLM 安全专题\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    LangChain入门\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    LangChain介绍\n",
      "Chunk 9: LangChain入门\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    LangChain介绍\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    LangChain模块学习\n",
      "Chunk 10: LangChain介绍\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    LangChain模块学习\n",
      "Chunk 11: LangChain模块学习\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    LangChain之Chains模块\n",
      "Chunk 12: LangChain之Chains模块\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    LangChain之Agents模块\n",
      "Chunk 13: LangChain之Agents模块\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    LangChain之Callback模块\n",
      "Chunk 14: LangChain之Callback模块\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    Embedding嵌入\n",
      "Chunk 15: Embedding嵌入\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    动手实现文档问答机器人\n",
      "Chunk 16: Embedding嵌入\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    动手实现文档问答机器人\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    LlamaIndex 概述\n",
      "Chunk 17: 动手实现文档问答机器人\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    LlamaIndex 概述\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    LlamaIndex介绍\n",
      "Chunk 18: LlamaIndex 概述\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    LlamaIndex介绍\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    LlamaIndex索引\n",
      "Chunk 19: LlamaIndex介绍\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    LlamaIndex索引\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    动手实现企业知识库\n",
      "Chunk 20: LlamaIndex索引\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    动手实现企业知识库\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    HuggingGPT 实现\n",
      "Chunk 21: 动手实现企业知识库\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    HuggingGPT 实现\n",
      "Chunk 22: 动手实现企业知识库\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    HuggingGPT 实现\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    HuggingFace 介绍\n",
      "Chunk 23: HuggingFace 介绍\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    transformers 库基础组件\n",
      "Chunk 24: transformers 库基础组件\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    多模态任务设计\n",
      "Chunk 25: 多模态任务设计\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    动手实现 HuggingGPT\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    LLMOps 专题\n",
      "Chunk 26: LLMOps 专题\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    LLMOps 介绍\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    Model 模型层\n",
      "Chunk 27: LLMOps 介绍\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    Model 模型层\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    Prompt 提示层\n",
      "Chunk 28: Model 模型层\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    Prompt 提示层\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    狭义LLMOps\n",
      "Chunk 29: Prompt 提示层\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    狭义LLMOps\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    Agent 专题\n",
      "Chunk 30: 狭义LLMOps\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    Agent 专题\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    Agent 介绍\n",
      "Chunk 31: Agent 专题\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    Agent 介绍\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    Agent 项目跟踪\n",
      "Chunk 32: Agent 介绍\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    Agent 项目跟踪\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    Multi-Agent 系统\n",
      "Chunk 33: Multi-Agent 系统\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    RAG专题\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    数据索引环节\n",
      "Chunk 34: RAG专题\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    数据索引环节\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    检索环节\n",
      "Chunk 35: 数据索引环节\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    检索环节\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    生成环节\n",
      "Chunk 36: 检索环节\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    生成环节\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    LLM 应用评估与测试\n",
      "Chunk 37: 生成环节\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    LLM 应用评估与测试\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    如何评估一个大语言模型\n",
      "Chunk 38: 如何评估一个大语言模型\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    基于大模型的Agent进行测试评估\n",
      "Chunk 39: 基于大模型的Agent进行测试评估\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    RAG系统效果评估\n",
      "Chunk 40: RAG系统效果评估\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    国内模型厂商API解读\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    六家大模型能力比较\n",
      "Chunk 41: 国内模型厂商API解读\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    六家大模型能力比较\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    MiniMax大模型开发\n",
      "Chunk 42: 六家大模型能力比较\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    MiniMax大模型开发\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    智谱AI大模型开发\n",
      "Chunk 43: MiniMax大模型开发\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    智谱AI大模型开发\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    MoonShot大模型开发\n",
      "Chunk 44: 智谱AI大模型开发\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    MoonShot大模型开发\n",
      "Chunk 45: 智谱AI大模型开发\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    MoonShot大模型开发\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    基于大型语言模型的生成式AI\n",
      "Chunk 46: 基于大型语言模型的生成式AI\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    课程介绍\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    参考资料\n",
      "Chunk 47: 课程介绍\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    参考资料\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    A16Z推荐的AI学习清单\n",
      "Chunk 48: 参考资料\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    A16Z推荐的AI学习清单\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    Prompt专题\n",
      "Chunk 49: A16Z推荐的AI学习清单\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    Prompt专题\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    一些课程资料汇总\n",
      "Chunk 50: Prompt专题\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "            \n",
      "                    \n",
      "                    一些课程资料汇总\n",
      "            \n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "            本书使用 GitBook 发布\n",
      "        \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "OpenAI 文档解读\n",
      "Chunk 51: 本书使用 GitBook 发布\n",
      "        \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "OpenAI 文档解读\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "本电子书开源，欢迎 star 🌟，关注《LLM 应用开发实践笔记》\n",
      "我的新书《LangChain编程从入门到实践》 已经开售！推荐正在学习AI应用开发的朋友购买阅读！\n",
      " \n",
      "OpenAI 文档解读\n",
      "OpenAI 文档涉及内容众多，而且这里已经有了中文翻译，需要详细了解的可以自行前往阅读。我这里会重点选取高频使用的 API 进行说明以及对GPT最佳实践主题进行解读。\n",
      "Chunk 52: 本电子书开源，欢迎 star 🌟，关注《LLM 应用开发实践笔记》\n",
      "我的新书《LangChain编程从入门到实践》 已经开售！推荐正在学习AI应用开发的朋友购买阅读！\n",
      " \n",
      "OpenAI 文档解读\n",
      "OpenAI 文档涉及内容众多，而且这里已经有了中文翻译，需要详细了解的可以自行前往阅读。我这里会重点选取高频使用的 API 进行说明以及对GPT最佳实践主题进行解读。\n",
      "\n",
      "这篇文章中个人结合自己的实践经验把 OpenAI 官方文档解读一遍。但是原文档涉及内容众多，包括微调，嵌入（Embeddings）等众多主题，我这里重点挑选自己开发高频使用到的，需要详细了解的可以自行前往官网阅读。\n",
      "Chunk 53: 这篇文章中个人结合自己的实践经验把 OpenAI 官方文档解读一遍。但是原文档涉及内容众多，包括微调，嵌入（Embeddings）等众多主题，我这里重点挑选自己开发高频使用到的，需要详细了解的可以自行前往官网阅读。\n",
      "\n",
      "API介绍\n",
      "Chunk 54: 所有 API 演示均使用 Python 代码作为示例，所以确保已经安装官方 Python 包：pip install openai，同时配置 API 密钥的环境变量 OPENAI_API_KEY。\n",
      "认证：OpenAI API 使用 API 密钥进行身份验证， API密钥页面可以获取使用的 API 密钥。除了密钥，对于属于多个组织的用户，可以传递一个Requesting organization字段（可以在组织设置页面上找到组织ID）来指定用于 API请求的组织，这些API请求的使用将计入指定组织的订阅配额。\n",
      " import os\n",
      " import openai\n",
      "Chunk 55: 认证：OpenAI API 使用 API 密钥进行身份验证， API密钥页面可以获取使用的 API 密钥。除了密钥，对于属于多个组织的用户，可以传递一个Requesting organization字段（可以在组织设置页面上找到组织ID）来指定用于 API请求的组织，这些API请求的使用将计入指定组织的订阅配额。\n",
      " import os\n",
      " import openai\n",
      " # openai.organization = \"org-gth0C8mT2wnKealyDkrSrpQk\"\n",
      " openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
      "Chunk 56: import os\n",
      " import openai\n",
      " # openai.organization = \"org-gth0C8mT2wnKealyDkrSrpQk\"\n",
      " openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
      " openai.Model.list()\n",
      "Chunk 57: Chat Completions 会话补全\n",
      "这个是使用频次最高的接口，几乎当前所有的套壳ChatGPT应用都是基于这个接口封装的，所以将其放在第一个。给定一组描述对话的消息列表，模型将返回一个回复。\n",
      "import os\n",
      "import openai\n",
      "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
      "Chunk 58: # https://api.openai.com/v1/chat/completions\n",
      "completion = openai.ChatCompletion.create(\n",
      "  model=\"gpt-3.5-turbo\",\n",
      "  messages=[\n",
      "    {\"role\": \"user\", \"content\": \"Hello!\"}\n",
      "  ]\n",
      ")\n",
      "\n",
      "print(completion.choices[0].message)\n",
      "Chunk 59: 响应 ：\n",
      "{\n",
      "  \"id\": \"chatcmpl-123\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1677652288,\n",
      "  \"choices\": [{\n",
      "    \"index\": 0,\n",
      "    \"message\": {\n",
      "      \"role\": \"assistant\",\n",
      "      \"content\": \"\\n\\nHello there, how may I assist you today?\",\n",
      "    },\n",
      "    \"finish_reason\": \"stop\"\n",
      "  }],\n",
      "  \"usage\": {\n",
      "Chunk 60: \"choices\": [{\n",
      "    \"index\": 0,\n",
      "    \"message\": {\n",
      "      \"role\": \"assistant\",\n",
      "      \"content\": \"\\n\\nHello there, how may I assist you today?\",\n",
      "    },\n",
      "    \"finish_reason\": \"stop\"\n",
      "  }],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 9,\n",
      "    \"completion_tokens\": 12,\n",
      "    \"total_tokens\": 21\n",
      "  }\n",
      "}\n",
      "Chunk 61: Request body(常用入参详解) ：\n",
      "\n",
      "\n",
      "model （string，必填）\n",
      "要使用的模型ID。有关哪些模型适用于Chat API的详细信息，请查看 模型端点兼容性表\n",
      "\n",
      "messages （array，必填）\n",
      "迄今为止描述对话的消息列表\n",
      "\n",
      "role （string，必填）\n",
      "发送此消息的角色。system 、user 或 assistant 之一（一般用 user 发送用户问题，system 发送给模型提示信息）\n",
      "\n",
      "content （string，必填）\n",
      "消息的内容\n",
      "Chunk 62: messages （array，必填）\n",
      "迄今为止描述对话的消息列表\n",
      "\n",
      "role （string，必填）\n",
      "发送此消息的角色。system 、user 或 assistant 之一（一般用 user 发送用户问题，system 发送给模型提示信息）\n",
      "\n",
      "content （string，必填）\n",
      "消息的内容\n",
      "\n",
      "name （string，选填）\n",
      "此消息的发送者姓名。可以包含 a-z、A-Z、0-9 和下划线，最大长度为 64 个字符\n",
      "Chunk 63: content （string，必填）\n",
      "消息的内容\n",
      "\n",
      "name （string，选填）\n",
      "此消息的发送者姓名。可以包含 a-z、A-Z、0-9 和下划线，最大长度为 64 个字符\n",
      "\n",
      "\n",
      "\n",
      "stream （boolean，选填，是否按流的方式发送内容）\n",
      "当它设置为 true 时，API 会以 SSE（ Server Side Event ）方式返回内容。SSE 本质上是一个长链接，会持续不断地输出内容直到完成响应。如果不是做实时聊天，默认false即可。请参考OpenAI Cookbook 以获取 示例代码。\n",
      "Chunk 64: stream （boolean，选填，是否按流的方式发送内容）\n",
      "当它设置为 true 时，API 会以 SSE（ Server Side Event ）方式返回内容。SSE 本质上是一个长链接，会持续不断地输出内容直到完成响应。如果不是做实时聊天，默认false即可。请参考OpenAI Cookbook 以获取 示例代码。\n",
      "\n",
      "max_tokens （integer，选填）\n",
      "在聊天补全中生成的最大 tokens 数。\n",
      "输入token和生成的token的总长度受模型上下文长度的限制。\n",
      "Chunk 65: max_tokens （integer，选填）\n",
      "在聊天补全中生成的最大 tokens 数。\n",
      "输入token和生成的token的总长度受模型上下文长度的限制。\n",
      "\n",
      "temperature （number，选填，默认是 1）\n",
      "采样温度，在 0和 2 之间。\n",
      "较高的值，如0.8会使输出更随机，而较低的值，如0.2会使其更加集中和确定性。\n",
      "通常建议修改这个（temperature ）或者 top_p ，但两者不能同时存在，二选一。\n",
      "Chunk 66: Completions （文本和代码）补全\n",
      "给定一个提示，模型将返回一个或多个预测的补全，并且还可以在每个位置返回替代 token 的概率。\n",
      "  import os\n",
      "  import openai\n",
      "  openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
      "  # https://api.openai.com/v1/completions\n",
      "  openai.Completion.create(\n",
      "    model=\"text-davinci-003\",\n",
      "    prompt=\"Say this is a test\",\n",
      "    max_tokens=7,\n",
      "Chunk 67: openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
      "  # https://api.openai.com/v1/completions\n",
      "  openai.Completion.create(\n",
      "    model=\"text-davinci-003\",\n",
      "    prompt=\"Say this is a test\",\n",
      "    max_tokens=7,\n",
      "    temperature=0\n",
      "  )\n",
      "Chunk 68: 响应 ：\n",
      "  \"id\": \"cmpl-uqkvlQyYK7bGYrRHQ0eXlWi7\",\n",
      "  \"object\": \"text_completion\",\n",
      "  \"created\": 1589478378,\n",
      "  \"model\": \"text-davinci-003\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"text\": \"\\n\\nThis is indeed a test\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"finish_reason\": \"length\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "Chunk 69: \"model\": \"text-davinci-003\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"text\": \"\\n\\nThis is indeed a test\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"finish_reason\": \"length\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 5,\n",
      "    \"completion_tokens\": 7,\n",
      "    \"total_tokens\": 12\n",
      "  }\n",
      "}\n",
      "Chunk 70: Request body(入参详解) ：\n",
      "\n",
      "\n",
      "model （string，必填）\n",
      "要使用的模型的 ID。可以参考 模型端点兼容性表\n",
      "\n",
      "prompt （string or array，选填，Defaults to <|endoftext|>）\n",
      "生成补全的提示，编码为字符串、字符串数组、token数组或token数组数组。\n",
      "注意 <|endoftext|> 是模型在训练过程中看到的文档分隔符，所以如果没有指定提示符，模型将像从新文档的开头一样生成。\n",
      "Chunk 71: prompt （string or array，选填，Defaults to <|endoftext|>）\n",
      "生成补全的提示，编码为字符串、字符串数组、token数组或token数组数组。\n",
      "注意 <|endoftext|> 是模型在训练过程中看到的文档分隔符，所以如果没有指定提示符，模型将像从新文档的开头一样生成。\n",
      "\n",
      "stream （boolean，选填，默认 false）\n",
      "当它设置为 true 时，API 会以 SSE（ Server Side Event ）方式返回内容，即会不断地输出内容直到完成响应，流通过 data: [DONE] 消息终止。\n",
      "Chunk 72: stream （boolean，选填，默认 false）\n",
      "当它设置为 true 时，API 会以 SSE（ Server Side Event ）方式返回内容，即会不断地输出内容直到完成响应，流通过 data: [DONE] 消息终止。\n",
      "\n",
      "max_tokens （integer，选填，默认是 16）\n",
      "补全时要生成的最大 token 数。\n",
      "提示 max_tokens 的 token 计数不能超过模型的上下文长度。大多数模型的上下文长度为 2048 个token（最新模型除外，它支持 4096）\n",
      "Chunk 73: max_tokens （integer，选填，默认是 16）\n",
      "补全时要生成的最大 token 数。\n",
      "提示 max_tokens 的 token 计数不能超过模型的上下文长度。大多数模型的上下文长度为 2048 个token（最新模型除外，它支持 4096）\n",
      "\n",
      "temperature （number，选填，默认是1）\n",
      "使用哪个采样温度，在 0和2之间。\n",
      "较高的值，如0.8会使输出更随机，而较低的值，如0.2会使其更加集中和确定性。\n",
      "通常建议修改这个（temperature ）或 top_p 但两者不能同时存在，二选一。\n",
      "Chunk 74: temperature （number，选填，默认是1）\n",
      "使用哪个采样温度，在 0和2之间。\n",
      "较高的值，如0.8会使输出更随机，而较低的值，如0.2会使其更加集中和确定性。\n",
      "通常建议修改这个（temperature ）或 top_p 但两者不能同时存在，二选一。\n",
      "\n",
      "n （integer，选填，默认为 1）\n",
      "每个 prompt 生成的补全次数。\n",
      "注意：由于此参数会生成许多补全，因此它会快速消耗token配额。小心使用，并确保对 max_tokens 和 stop 进行合理的设置。\n",
      "Chunk 75: Embeddings 嵌入\n",
      "将一个给定输入转换为向量表示，提供给机器学习模型算法使用。\n",
      "import os\n",
      "import openai\n",
      "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
      "# https://api.openai.com/v1/embeddings\n",
      "openai.Embedding.create(\n",
      "  model=\"text-embedding-ada-002\",\n",
      "  input=\"The food was delicious and the waiter...\"\n",
      ")\n",
      "Chunk 76: 响应 ：\n",
      "{\n",
      "  \"object\": \"list\",\n",
      "  \"data\": [\n",
      "    {\n",
      "      \"object\": \"embedding\",\n",
      "      \"embedding\": [\n",
      "        0.0023064255,\n",
      "        -0.009327292,\n",
      "        .... (1536 floats total for ada-002)\n",
      "        -0.0028842222,\n",
      "      ],\n",
      "      \"index\": 0\n",
      "    }\n",
      "  ],\n",
      "  \"model\": \"text-embedding-ada-002\",\n",
      "  \"usage\": {\n",
      "Chunk 77: 0.0023064255,\n",
      "        -0.009327292,\n",
      "        .... (1536 floats total for ada-002)\n",
      "        -0.0028842222,\n",
      "      ],\n",
      "      \"index\": 0\n",
      "    }\n",
      "  ],\n",
      "  \"model\": \"text-embedding-ada-002\",\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 8,\n",
      "    \"total_tokens\": 8\n",
      "  }\n",
      "}\n",
      "Chunk 78: Request body(入参详解) ：\n",
      "\n",
      "\n",
      "model （string，必填）\n",
      "要使用的 模型ID，可以参考 模型端点兼容性表\n",
      "\n",
      "input （string or array，必填）\n",
      "输入文本以获取嵌入，编码为字符串或token数组。要在单个请求中获取多个输入的嵌入，请传递字符串数组或token数组的数组。每个输入长度不得超过 8192 个token。\n",
      "\n",
      "user （string，选填）\n",
      "一个唯一的标识符，代表终端用户，可以帮助OpenAI检测滥用。\n",
      "Chunk 79: Fine-tuning 微调\n",
      "使用自定义的特定训练数据，定制自己的模型。\n",
      "Create fine-tune\n",
      "创建一个微调作业，从给定的数据集中微调指定模型。\n",
      "import os\n",
      "import openai\n",
      "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
      "# POST https://api.openai.com/v1/fine-tunes\n",
      "openai.FineTune.create(training_file=\"file-XGinujblHPwGLSztz8cPS8XY\")\n",
      "Chunk 80: 响应（响应包括已入队的作业的详细信息，包括微调作业状态和完成后微调模型的名称）：\n",
      "{\n",
      "  \"id\": \"ft-AF1WoRqd3aJAHsqc9NY7iL8F\",\n",
      "  \"object\": \"fine-tune\",\n",
      "  \"model\": \"curie\",\n",
      "  \"created_at\": 1614807352,\n",
      "  \"events\": [\n",
      "    {\n",
      "      \"object\": \"fine-tune-event\",\n",
      "      \"created_at\": 1614807352,\n",
      "      \"level\": \"info\",\n",
      "Chunk 81: \"object\": \"fine-tune\",\n",
      "  \"model\": \"curie\",\n",
      "  \"created_at\": 1614807352,\n",
      "  \"events\": [\n",
      "    {\n",
      "      \"object\": \"fine-tune-event\",\n",
      "      \"created_at\": 1614807352,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Job enqueued. Waiting for jobs ahead to complete. Queue number: 0.\"\n",
      "    }\n",
      "  ],\n",
      "Chunk 82: {\n",
      "      \"object\": \"fine-tune-event\",\n",
      "      \"created_at\": 1614807352,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Job enqueued. Waiting for jobs ahead to complete. Queue number: 0.\"\n",
      "    }\n",
      "  ],\n",
      "  \"fine_tuned_model\": null,\n",
      "  \"hyperparams\": {\n",
      "    \"batch_size\": 4,\n",
      "    \"learning_rate_multiplier\": 0.1,\n",
      "Chunk 83: }\n",
      "  ],\n",
      "  \"fine_tuned_model\": null,\n",
      "  \"hyperparams\": {\n",
      "    \"batch_size\": 4,\n",
      "    \"learning_rate_multiplier\": 0.1,\n",
      "    \"n_epochs\": 4,\n",
      "    \"prompt_loss_weight\": 0.1,\n",
      "  },\n",
      "  \"organization_id\": \"org-...\",\n",
      "  \"result_files\": [],\n",
      "  \"status\": \"pending\",\n",
      "  \"validation_files\": [],\n",
      "  \"training_files\": [\n",
      "Chunk 84: \"n_epochs\": 4,\n",
      "    \"prompt_loss_weight\": 0.1,\n",
      "  },\n",
      "  \"organization_id\": \"org-...\",\n",
      "  \"result_files\": [],\n",
      "  \"status\": \"pending\",\n",
      "  \"validation_files\": [],\n",
      "  \"training_files\": [\n",
      "    {\n",
      "      \"id\": \"file-XGinujblHPwGLSztz8cPS8XY\",\n",
      "      \"object\": \"file\",\n",
      "      \"bytes\": 1547276,\n",
      "Chunk 85: \"result_files\": [],\n",
      "  \"status\": \"pending\",\n",
      "  \"validation_files\": [],\n",
      "  \"training_files\": [\n",
      "    {\n",
      "      \"id\": \"file-XGinujblHPwGLSztz8cPS8XY\",\n",
      "      \"object\": \"file\",\n",
      "      \"bytes\": 1547276,\n",
      "      \"created_at\": 1610062281,\n",
      "      \"filename\": \"my-data-train.jsonl\",\n",
      "      \"purpose\": \"fine-tune-train\"\n",
      "Chunk 86: \"object\": \"file\",\n",
      "      \"bytes\": 1547276,\n",
      "      \"created_at\": 1610062281,\n",
      "      \"filename\": \"my-data-train.jsonl\",\n",
      "      \"purpose\": \"fine-tune-train\"\n",
      "    }\n",
      "  ],\n",
      "  \"updated_at\": 1614807352,\n",
      "}\n",
      "Chunk 87: Request body(入参详解) ：\n",
      "\n",
      "\n",
      "training_file （string，必填）\n",
      "包含 训练数据 的已上传文件的ID。\n",
      "请参阅 upload file 以了解如何上传文件。\n",
      "数据集必须格式化为 JSONL文件，其中每个训练示例都是一个带有 “prompt” 和 “completion” keys 的 JSON对象。\n",
      "\n",
      "validation_file （string，选填）\n",
      "包含 验证数据 的已上传文件的ID。\n",
      "如果提供此文件，则数据将在微调期间定期用于生成验证指标。这些指标可以在 微调结果文件 中查看，训练和验证数据应该是互斥的。\n",
      "Chunk 88: validation_file （string，选填）\n",
      "包含 验证数据 的已上传文件的ID。\n",
      "如果提供此文件，则数据将在微调期间定期用于生成验证指标。这些指标可以在 微调结果文件 中查看，训练和验证数据应该是互斥的。\n",
      "\n",
      "model （string，选填，默认是curie）\n",
      "要微调的基础模型名称。\n",
      "可以选择其中之一：\"ada\"、\"babbage\"、\"curie\"、\"davinci\"，或 2022年4月21日 后创建的经过微调的模型。要了解这些模型的更多信息，请参阅 Models 文档。\n",
      "Chunk 89: model （string，选填，默认是curie）\n",
      "要微调的基础模型名称。\n",
      "可以选择其中之一：\"ada\"、\"babbage\"、\"curie\"、\"davinci\"，或 2022年4月21日 后创建的经过微调的模型。要了解这些模型的更多信息，请参阅 Models 文档。\n",
      "\n",
      "n_epochs （integer，选填，默认是4）\n",
      "训练模型的批次数。一个 epoch 指的是完整地遍历一次训练数据集\n",
      "Chunk 90: n_epochs （integer，选填，默认是4）\n",
      "训练模型的批次数。一个 epoch 指的是完整地遍历一次训练数据集\n",
      "\n",
      "batch_size （integer，选填）\n",
      "用于训练的批次大小，指的是每次迭代中同时处理的样本数量。\n",
      "默认情况下，批次大小将动态配置为训练集示例数量的约 0.2％，上限为256。\n",
      "通常，发现较大的批次大小对于更大的数据集效果更好。\n",
      "Chunk 91: learning_rate_multiplier （number，选填）\n",
      "用于训练的学习率倍增器。微调学习率是预训练时使用的原始学习率乘以此值得到的（🤖️微调学习率（Learning Rate）指的是神经网络在进行梯度下降优化算法时，每次更新参数的步长。学习率越大，神经网络的参数更新越快，但可能会导致优化过程不稳定甚至无法收敛；学习率越小，神经网络的参数更新越慢，但可能会导致优化过程过于缓慢或者陷入局部最优解。）\n",
      "Chunk 92: 用于训练的学习率倍增器。微调学习率是预训练时使用的原始学习率乘以此值得到的（🤖️微调学习率（Learning Rate）指的是神经网络在进行梯度下降优化算法时，每次更新参数的步长。学习率越大，神经网络的参数更新越快，但可能会导致优化过程不稳定甚至无法收敛；学习率越小，神经网络的参数更新越慢，但可能会导致优化过程过于缓慢或者陷入局部最优解。）\n",
      "默认情况下，学习率的倍增器为 0.05、0.1 或 0.2，具体取决于最终 batch_size（较大的批次大小通常使用较大的学习率效果更好），建议尝试在 0.02 到 0.2 范围内实验不同值以找出产生最佳结果的值。\n",
      "Chunk 93: prompt_loss_weight （number，选填，默认是0.01）\n",
      "\"prompt_loss_weight\" 是指在使用 Prompt-based Learning（基于提示的学习）方法进行训练时，用于调整提示损失（Prompt Loss）对总体损失（Total Loss）的相对权重。\n",
      "Prompt-based Learning 是一种利用人类先验知识来辅助神经网络学习的方法，其中提示损失是指利用人类先验知识设计的提示（Prompt）与模型生成的结果之间的损失。\n",
      "Chunk 94: Prompt-based Learning 是一种利用人类先验知识来辅助神经网络学习的方法，其中提示损失是指利用人类先验知识设计的提示（Prompt）与模型生成的结果之间的损失。\n",
      "在 Prompt-based Learning 中，通过调整 prompt_loss_weight 的大小来平衡总体损失和提示损失的贡献，从而使模型更好地利用人类先验知识进行预测。如果 prompt_loss_weight 较大，模型会更加依赖提示损失，更好地利用人类先验知识；如果 prompt_loss_weight 较小，模型会更加依赖总体损失，更好地适应当前数据集的特征和分布。\n",
      "Chunk 95: compute_classification_metrics （boolean，选填，默认是false）\n",
      "如果设置了，会在每个 epoch 结束时使用验证集计算特定于分类的指标，例如准确率和 F-1 分数。这些指标可以在 微调结果文件 中查看。为了计算分类指标，必须提供一个validation_file(验证文件)。\n",
      "此外，对于多类分类，必须指定 classification_n_classes；对于二元分类，则需要指定classification_positive_class。\n",
      "Chunk 96: suffix （string，选填，默认为 null）\n",
      "一个长度最多为 40个字符 的字符串，将被添加到微调模型名称中。\n",
      "例如，suffix  为 “custom-model-name” 会生成一个模型名称，如 ada:ft-your-org:custom-model-name-2022-02-15-04-21-04。\n",
      "Chunk 97: List fine-tunes\n",
      "列出所属组织下的微调作业列表\n",
      "import os\n",
      "import openai\n",
      "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
      "# GET https://api.openai.com/v1/fine-tunes\n",
      "openai.FineTune.list()\n",
      "Chunk 98: 响应 ：\n",
      "{\n",
      "  \"object\": \"list\",\n",
      "  \"data\": [\n",
      "    {\n",
      "      \"id\": \"ft-AF1WoRqd3aJAHsqc9NY7iL8F\",\n",
      "      \"object\": \"fine-tune\",\n",
      "      \"model\": \"curie\",\n",
      "      \"created_at\": 1614807352,\n",
      "      \"fine_tuned_model\": null,\n",
      "      \"hyperparams\": { ... },\n",
      "      \"organization_id\": \"org-...\",\n",
      "      \"result_files\": [],\n",
      "Chunk 99: \"model\": \"curie\",\n",
      "      \"created_at\": 1614807352,\n",
      "      \"fine_tuned_model\": null,\n",
      "      \"hyperparams\": { ... },\n",
      "      \"organization_id\": \"org-...\",\n",
      "      \"result_files\": [],\n",
      "      \"status\": \"pending\",\n",
      "      \"validation_files\": [],\n",
      "      \"training_files\": [ { ... } ],\n",
      "Chunk 100: \"hyperparams\": { ... },\n",
      "      \"organization_id\": \"org-...\",\n",
      "      \"result_files\": [],\n",
      "      \"status\": \"pending\",\n",
      "      \"validation_files\": [],\n",
      "      \"training_files\": [ { ... } ],\n",
      "      \"updated_at\": 1614807352,\n",
      "    },\n",
      "    { ... },\n",
      "    { ... }\n",
      "  ]\n",
      "}\n",
      "Chunk 101: Retrieve fine-tune\n",
      "获取有关微调作业的信息\n",
      "import os\n",
      "import openai\n",
      "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
      "# https://api.openai.com/v1/fine-tunes/{fine_tune_id}\n",
      "openai.FineTune.retrieve(id=\"ft-AF1WoRqd3aJAHsqc9NY7iL8F\")\n",
      "Chunk 102: 响应 ：\n",
      "{\n",
      "  \"id\": \"ft-AF1WoRqd3aJAHsqc9NY7iL8F\",\n",
      "  \"object\": \"fine-tune\",\n",
      "  \"model\": \"curie\",\n",
      "  \"created_at\": 1614807352,\n",
      "  \"events\": [\n",
      "    {\n",
      "      \"object\": \"fine-tune-event\",\n",
      "      \"created_at\": 1614807352,\n",
      "      \"level\": \"info\",\n",
      "Chunk 103: \"object\": \"fine-tune\",\n",
      "  \"model\": \"curie\",\n",
      "  \"created_at\": 1614807352,\n",
      "  \"events\": [\n",
      "    {\n",
      "      \"object\": \"fine-tune-event\",\n",
      "      \"created_at\": 1614807352,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Job enqueued. Waiting for jobs ahead to complete. Queue number: 0.\"\n",
      "    },\n",
      "    {\n",
      "Chunk 104: {\n",
      "      \"object\": \"fine-tune-event\",\n",
      "      \"created_at\": 1614807352,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Job enqueued. Waiting for jobs ahead to complete. Queue number: 0.\"\n",
      "    },\n",
      "    {\n",
      "      \"object\": \"fine-tune-event\",\n",
      "      \"created_at\": 1614807356,\n",
      "      \"level\": \"info\",\n",
      "Chunk 105: \"message\": \"Job enqueued. Waiting for jobs ahead to complete. Queue number: 0.\"\n",
      "    },\n",
      "    {\n",
      "      \"object\": \"fine-tune-event\",\n",
      "      \"created_at\": 1614807356,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Job started.\"\n",
      "    },\n",
      "    {\n",
      "      \"object\": \"fine-tune-event\",\n",
      "Chunk 106: },\n",
      "    {\n",
      "      \"object\": \"fine-tune-event\",\n",
      "      \"created_at\": 1614807356,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Job started.\"\n",
      "    },\n",
      "    {\n",
      "      \"object\": \"fine-tune-event\",\n",
      "      \"created_at\": 1614807861,\n",
      "      \"level\": \"info\",\n",
      "Chunk 107: \"created_at\": 1614807356,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Job started.\"\n",
      "    },\n",
      "    {\n",
      "      \"object\": \"fine-tune-event\",\n",
      "      \"created_at\": 1614807861,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Uploaded snapshot: curie:ft-acmeco-2021-03-03-21-44-20.\"\n",
      "    },\n",
      "    {\n",
      "Chunk 108: },\n",
      "    {\n",
      "      \"object\": \"fine-tune-event\",\n",
      "      \"created_at\": 1614807861,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Uploaded snapshot: curie:ft-acmeco-2021-03-03-21-44-20.\"\n",
      "    },\n",
      "    {\n",
      "      \"object\": \"fine-tune-event\",\n",
      "      \"created_at\": 1614807864,\n",
      "      \"level\": \"info\",\n",
      "Chunk 109: \"message\": \"Uploaded snapshot: curie:ft-acmeco-2021-03-03-21-44-20.\"\n",
      "    },\n",
      "    {\n",
      "      \"object\": \"fine-tune-event\",\n",
      "      \"created_at\": 1614807864,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Uploaded result files: file-QQm6ZpqdNwAaVC3aSz5sWwLT.\"\n",
      "    },\n",
      "    {\n",
      "      \"object\": \"fine-tune-event\",\n",
      "Chunk 110: \"created_at\": 1614807864,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Uploaded result files: file-QQm6ZpqdNwAaVC3aSz5sWwLT.\"\n",
      "    },\n",
      "    {\n",
      "      \"object\": \"fine-tune-event\",\n",
      "      \"created_at\": 1614807864,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Job succeeded.\"\n",
      "    }\n",
      "  ],\n",
      "Chunk 111: },\n",
      "    {\n",
      "      \"object\": \"fine-tune-event\",\n",
      "      \"created_at\": 1614807864,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Job succeeded.\"\n",
      "    }\n",
      "  ],\n",
      "  \"fine_tuned_model\": \"curie:ft-acmeco-2021-03-03-21-44-20\",\n",
      "  \"hyperparams\": {\n",
      "    \"batch_size\": 4,\n",
      "    \"learning_rate_multiplier\": 0.1,\n",
      "Chunk 112: \"message\": \"Job succeeded.\"\n",
      "    }\n",
      "  ],\n",
      "  \"fine_tuned_model\": \"curie:ft-acmeco-2021-03-03-21-44-20\",\n",
      "  \"hyperparams\": {\n",
      "    \"batch_size\": 4,\n",
      "    \"learning_rate_multiplier\": 0.1,\n",
      "    \"n_epochs\": 4,\n",
      "    \"prompt_loss_weight\": 0.1,\n",
      "  },\n",
      "  \"organization_id\": \"org-...\",\n",
      "  \"result_files\": [\n",
      "    {\n",
      "Chunk 113: \"hyperparams\": {\n",
      "    \"batch_size\": 4,\n",
      "    \"learning_rate_multiplier\": 0.1,\n",
      "    \"n_epochs\": 4,\n",
      "    \"prompt_loss_weight\": 0.1,\n",
      "  },\n",
      "  \"organization_id\": \"org-...\",\n",
      "  \"result_files\": [\n",
      "    {\n",
      "      \"id\": \"file-QQm6ZpqdNwAaVC3aSz5sWwLT\",\n",
      "      \"object\": \"file\",\n",
      "      \"bytes\": 81509,\n",
      "Chunk 114: \"prompt_loss_weight\": 0.1,\n",
      "  },\n",
      "  \"organization_id\": \"org-...\",\n",
      "  \"result_files\": [\n",
      "    {\n",
      "      \"id\": \"file-QQm6ZpqdNwAaVC3aSz5sWwLT\",\n",
      "      \"object\": \"file\",\n",
      "      \"bytes\": 81509,\n",
      "      \"created_at\": 1614807863,\n",
      "      \"filename\": \"compiled_results.csv\",\n",
      "      \"purpose\": \"fine-tune-results\"\n",
      "Chunk 115: \"object\": \"file\",\n",
      "      \"bytes\": 81509,\n",
      "      \"created_at\": 1614807863,\n",
      "      \"filename\": \"compiled_results.csv\",\n",
      "      \"purpose\": \"fine-tune-results\"\n",
      "    }\n",
      "  ],\n",
      "  \"status\": \"succeeded\",\n",
      "  \"validation_files\": [],\n",
      "  \"training_files\": [\n",
      "    {\n",
      "      \"id\": \"file-XGinujblHPwGLSztz8cPS8XY\",\n",
      "Chunk 116: \"purpose\": \"fine-tune-results\"\n",
      "    }\n",
      "  ],\n",
      "  \"status\": \"succeeded\",\n",
      "  \"validation_files\": [],\n",
      "  \"training_files\": [\n",
      "    {\n",
      "      \"id\": \"file-XGinujblHPwGLSztz8cPS8XY\",\n",
      "      \"object\": \"file\",\n",
      "      \"bytes\": 1547276,\n",
      "      \"created_at\": 1610062281,\n",
      "      \"filename\": \"my-data-train.jsonl\",\n",
      "Chunk 117: \"training_files\": [\n",
      "    {\n",
      "      \"id\": \"file-XGinujblHPwGLSztz8cPS8XY\",\n",
      "      \"object\": \"file\",\n",
      "      \"bytes\": 1547276,\n",
      "      \"created_at\": 1610062281,\n",
      "      \"filename\": \"my-data-train.jsonl\",\n",
      "      \"purpose\": \"fine-tune-train\"\n",
      "    }\n",
      "  ],\n",
      "  \"updated_at\": 1614807865,\n",
      "}\n",
      "Chunk 118: Cancel fine-tune\n",
      "立即取消微调工作\n",
      "import os\n",
      "import openai\n",
      "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
      "# https://api.openai.com/v1/fine-tunes/{fine_tune_id}/cancel\n",
      "openai.FineTune.cancel(id=\"ft-AF1WoRqd3aJAHsqc9NY7iL8F\")\n",
      "Chunk 119: 响应 ：\n",
      "{\n",
      "  \"id\": \"ft-xhrpBbvVUzYGo8oUO1FY4nI7\",\n",
      "  \"object\": \"fine-tune\",\n",
      "  \"model\": \"curie\",\n",
      "  \"created_at\": 1614807770,\n",
      "  \"events\": [ { ... } ],\n",
      "  \"fine_tuned_model\": null,\n",
      "  \"hyperparams\": { ... },\n",
      "  \"organization_id\": \"org-...\",\n",
      "  \"result_files\": [],\n",
      "  \"status\": \"cancelled\",\n",
      "Chunk 120: \"created_at\": 1614807770,\n",
      "  \"events\": [ { ... } ],\n",
      "  \"fine_tuned_model\": null,\n",
      "  \"hyperparams\": { ... },\n",
      "  \"organization_id\": \"org-...\",\n",
      "  \"result_files\": [],\n",
      "  \"status\": \"cancelled\",\n",
      "  \"validation_files\": [],\n",
      "  \"training_files\": [\n",
      "    {\n",
      "      \"id\": \"file-XGinujblHPwGLSztz8cPS8XY\",\n",
      "Chunk 121: \"organization_id\": \"org-...\",\n",
      "  \"result_files\": [],\n",
      "  \"status\": \"cancelled\",\n",
      "  \"validation_files\": [],\n",
      "  \"training_files\": [\n",
      "    {\n",
      "      \"id\": \"file-XGinujblHPwGLSztz8cPS8XY\",\n",
      "      \"object\": \"file\",\n",
      "      \"bytes\": 1547276,\n",
      "      \"created_at\": 1610062281,\n",
      "      \"filename\": \"my-data-train.jsonl\",\n",
      "Chunk 122: \"training_files\": [\n",
      "    {\n",
      "      \"id\": \"file-XGinujblHPwGLSztz8cPS8XY\",\n",
      "      \"object\": \"file\",\n",
      "      \"bytes\": 1547276,\n",
      "      \"created_at\": 1610062281,\n",
      "      \"filename\": \"my-data-train.jsonl\",\n",
      "      \"purpose\": \"fine-tune-train\"\n",
      "    }\n",
      "  ],\n",
      "  \"updated_at\": 1614807789,\n",
      "}\n",
      "Chunk 123: List fine-tune events\n",
      "获取微调作业各阶段运行状态（事件）详情\n",
      "import os\n",
      "import openai\n",
      "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
      "# https://api.openai.com/v1/fine-tunes/{fine_tune_id}/events\n",
      "openai.FineTune.list_events(id=\"ft-AF1WoRqd3aJAHsqc9NY7iL8F\")\n",
      "Chunk 124: 响应 ：\n",
      "{\n",
      "  \"object\": \"list\",\n",
      "  \"data\": [\n",
      "    {\n",
      "      \"object\": \"fine-tune-event\",\n",
      "      \"created_at\": 1614807352,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Job enqueued. Waiting for jobs ahead to complete. Queue number: 0.\"\n",
      "    },\n",
      "    {\n",
      "      \"object\": \"fine-tune-event\",\n",
      "Chunk 125: \"created_at\": 1614807352,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Job enqueued. Waiting for jobs ahead to complete. Queue number: 0.\"\n",
      "    },\n",
      "    {\n",
      "      \"object\": \"fine-tune-event\",\n",
      "      \"created_at\": 1614807356,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Job started.\"\n",
      "    },\n",
      "    {\n",
      "Chunk 126: },\n",
      "    {\n",
      "      \"object\": \"fine-tune-event\",\n",
      "      \"created_at\": 1614807356,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Job started.\"\n",
      "    },\n",
      "    {\n",
      "      \"object\": \"fine-tune-event\",\n",
      "      \"created_at\": 1614807861,\n",
      "      \"level\": \"info\",\n",
      "Chunk 127: \"created_at\": 1614807356,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Job started.\"\n",
      "    },\n",
      "    {\n",
      "      \"object\": \"fine-tune-event\",\n",
      "      \"created_at\": 1614807861,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Uploaded snapshot: curie:ft-acmeco-2021-03-03-21-44-20.\"\n",
      "    },\n",
      "    {\n",
      "Chunk 128: },\n",
      "    {\n",
      "      \"object\": \"fine-tune-event\",\n",
      "      \"created_at\": 1614807861,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Uploaded snapshot: curie:ft-acmeco-2021-03-03-21-44-20.\"\n",
      "    },\n",
      "    {\n",
      "      \"object\": \"fine-tune-event\",\n",
      "      \"created_at\": 1614807864,\n",
      "      \"level\": \"info\",\n",
      "Chunk 129: \"message\": \"Uploaded snapshot: curie:ft-acmeco-2021-03-03-21-44-20.\"\n",
      "    },\n",
      "    {\n",
      "      \"object\": \"fine-tune-event\",\n",
      "      \"created_at\": 1614807864,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Uploaded result files: file-QQm6ZpqdNwAaVC3aSz5sWwLT.\"\n",
      "    },\n",
      "    {\n",
      "      \"object\": \"fine-tune-event\",\n",
      "Chunk 130: \"created_at\": 1614807864,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Uploaded result files: file-QQm6ZpqdNwAaVC3aSz5sWwLT.\"\n",
      "    },\n",
      "    {\n",
      "      \"object\": \"fine-tune-event\",\n",
      "      \"created_at\": 1614807864,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Job succeeded.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Chunk 131: Query parameters ：\n",
      "\n",
      "\n",
      "stream （boolean，选填）\n",
      "对于微调作业运行状态是否以事件流的方式返回\n",
      "如果设置为 true，则会不断地输出微调作业运行最新状态信息，直到微调作业完成（成功、取消或失败）时，以 data：[DONE] 消息终止。\n",
      "如果设置为 false，则仅返回到目前为止生成的事件。\n",
      "Chunk 132: Delete fine-tune model\n",
      "删除微调的模型（前提是有权限）\n",
      "import os\n",
      "import openai\n",
      "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
      "# https://api.openai.com/v1/models/{model}\n",
      "openai.Model.delete(\"curie:ft-acmeco-2021-03-03-21-44-20\")\n",
      "Chunk 133: 响应 ：\n",
      "{\n",
      "  \"id\": \"curie:ft-acmeco-2021-03-03-21-44-20\",\n",
      "  \"object\": \"model\",\n",
      "  \"deleted\": true\n",
      "}\n",
      "Chunk 134: Models 模型管理\n",
      "列出并描述 API 中可用的各种模型，可以参考 模型文档 以了解可用的模型以及它们之间的差异。\n",
      "列出模型\n",
      "列出当前可用的模型，并提供有关每个模型的基本信息，例如所有者和可用性。\n",
      "import os\n",
      "import openai\n",
      "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
      "# https://api.openai.com/v1/models\n",
      "openai.Model.list()\n",
      "Chunk 135: 响应\n",
      "：\n",
      "{\n",
      "  \"data\": [\n",
      "    {\n",
      "      \"id\": \"model-id-0\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"organization-owner\",\n",
      "      \"permission\": [...]\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"model-id-1\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"organization-owner\",\n",
      "      \"permission\": [...]\n",
      "    },\n",
      "    {\n",
      "Chunk 136: \"permission\": [...]\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"model-id-1\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"organization-owner\",\n",
      "      \"permission\": [...]\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"model-id-2\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"openai\",\n",
      "      \"permission\": [...]\n",
      "    },\n",
      "  ],\n",
      "Chunk 137: \"owned_by\": \"organization-owner\",\n",
      "      \"permission\": [...]\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"model-id-2\",\n",
      "      \"object\": \"model\",\n",
      "      \"owned_by\": \"openai\",\n",
      "      \"permission\": [...]\n",
      "    },\n",
      "  ],\n",
      "  \"object\": \"list\"\n",
      "}\n",
      "Chunk 138: 检索模型详情\n",
      "检索模型实例，提供有关模型的基本信息，例如所有者和权限。其中，model 为必填的字符串类型，用于此请求的模型的 ID。\n",
      "import os\n",
      "import openai\n",
      "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
      "# https://api.openai.com/v1/models/{model}\n",
      "openai.Model.retrieve(\"text-davinci-003\")\n",
      "Chunk 139: 响应 ：\n",
      "{\n",
      "  \"id\": \"text-davinci-003\",\n",
      "  \"object\": \"model\",\n",
      "  \"owned_by\": \"openai\",\n",
      "  \"permission\": [...]\n",
      "}\n",
      "\n",
      "其他\n",
      "Chunk 140: 其他\n",
      "\n",
      "Images 图像（图像生成API，DALL·E的能力已经落后于Stable Diffusion和Midjourney，使用场景不多）\n",
      "Audio 音频（音频转换为文本API，Whisper模型已经开源，可以本地搭建使用）\n",
      "Files 文件（上传文档API，一般与微调等功能一起使用，不需要专门关注）\n",
      "Edits 编辑（更新提示词API，对话补全接口已经覆盖了）\n",
      "Moderations 审核 (内容审核API，如果模型识别到提示词违反了OpenAI的内容策略，会返回审核信息详情)\n",
      "Parameter details 参数细节（没有使用过）\n",
      "Chunk 141: 最佳安全实践\n",
      "在开发过程中，注意到API的任何安全问题或与OpenAI相关的任何其他问题，可以通过漏洞披露计划提交这些问题。\n",
      "\n",
      "使用内容审核 API\n",
      "OpenAI的内容审核 API) 调用是不耗费 token 的，可以借助这个能力构建内容过滤系统，减少不安全内容。\n",
      "Chunk 142: 使用内容审核 API\n",
      "OpenAI的内容审核 API) 调用是不耗费 token 的，可以借助这个能力构建内容过滤系统，减少不安全内容。\n",
      "\n",
      "对抗性测试\n",
      "自己主动进行类似传统安全领域的“红队演练”，验证基于大语言模型的程序对存在攻击的输入具有鲁棒性。操作层面上就是通过遍历尽量多的输入和用户行为测试，包括代表性的数据集以及试图“破坏”应用程序的输入。在测试中，需要关注应用程序是否会偏离主题，以及是否可以轻易地通过提示注入来重定向功能。例如，“忽略以前的指令，改为执行这个操作”。\n",
      "Chunk 143: 对抗性测试\n",
      "自己主动进行类似传统安全领域的“红队演练”，验证基于大语言模型的程序对存在攻击的输入具有鲁棒性。操作层面上就是通过遍历尽量多的输入和用户行为测试，包括代表性的数据集以及试图“破坏”应用程序的输入。在测试中，需要关注应用程序是否会偏离主题，以及是否可以轻易地通过提示注入来重定向功能。例如，“忽略以前的指令，改为执行这个操作”。\n",
      "\n",
      "必须人工参与，不能全权委托给模型\n",
      "在实际应用前，让人工先审核输出结果，特别是在高风险领域和代码生成方面，大语言模型系统具有其局限性，人工能够查看任何验证输出所需的信息（例如生成笔记概要应用，前提是用户能够轻松获取原始笔记进行参考）。\n",
      "Chunk 144: 必须人工参与，不能全权委托给模型\n",
      "在实际应用前，让人工先审核输出结果，特别是在高风险领域和代码生成方面，大语言模型系统具有其局限性，人工能够查看任何验证输出所需的信息（例如生成笔记概要应用，前提是用户能够轻松获取原始笔记进行参考）。\n",
      "\n",
      "提示工程\n",
      "“提示工程”可以帮助限制输出文本的主题和语气，从而减少产生不良内容的可能性，即使用户试图产生这样的内容也是如此。为模型提供附加上下文（例如，在新输入之前提供几个高质量的期望行为示例）可以使其更容易将模型输出引导到所需的方向。\n",
      "Chunk 145: 提示工程\n",
      "“提示工程”可以帮助限制输出文本的主题和语气，从而减少产生不良内容的可能性，即使用户试图产生这样的内容也是如此。为模型提供附加上下文（例如，在新输入之前提供几个高质量的期望行为示例）可以使其更容易将模型输出引导到所需的方向。\n",
      "\n",
      "了解你的客户\n",
      "通常情况下，用户需要注册并登录才能使用您的服务。将此服务与现有账户（例如Gmail、LinkedIn或Facebook登录）链接可能会有所帮助，但并不适用于所有用例。要进一步降低风险，可以要求提供信用卡或身份证明等信息。\n",
      "Chunk 146: 限制用户输入并限制输出token数量\n",
      "限制用户在提示中输入的文本数量有助于避免提示注入。限制输出token的数量有助于减少误用的可能性。\n",
      "缩小输入或输出范围，特别是从可信来源中获取，可以减少应用程序中可能发生的误用程度。\n",
      "通过验证的下拉字段（例如，维基百科上的电影列表）允许用户输入可能比允许开放式文本输入更安全。\n",
      "在可能的情况下，从后端返回一组经过验证的材料的输出可能比返回全新生成的内容更安全（例如，将客户查询路由到最匹配的现有客户支持文章，而不是尝试从头回答查询）。\n",
      "Chunk 147: 允许用户报告问题\n",
      "通常情况下，用户应该有一个方便易用的方法来报告应用程序功能不当或其他相关问题（例如，列出的电子邮件地址、提交工单等）。这种方法应该由人工进行监控，并根据情况作出回应。\n",
      "\n",
      "了解和沟通局限性\n",
      "语言模型可能会出现诸如产生不准确信息、冒犯性输出、偏见等问题，这些问题可能需要进行显著的修改才能适用于每个用例。在考虑使用语言模型之前，请评估模型是否适合您的目的，并在广泛的潜在输入上测试API的性能，以确定API性能可能下降的情况。同时，考虑您的客户群体以及他们将要使用的输入范围，并确保他们的期望得到适当的调整。\n",
      "Chunk 148: 终端用户ID\n",
      "在请求中发送终端用户ID可以帮助OpenAI监测和检测滥用行为，这是一个有用的工具，这可以让OpenAI在检测到应用程序违反任何政策的情况下，提供更具有操作性的反馈。\n",
      "这些ID应该是一个字符串，用于唯一标识每个用户。建议对其用户名或电子邮件地址进行哈希处理，以避免发送任何身份信息。如果向非登录用户提供产品预览，可以发送一个会话ID。\n",
      "可以通过 user 参数在API请求中包含终端用户ID，如下所示：\n",
      "response = openai.Completion.create(\n",
      "  model=\"text-davinci-003\",\n",
      "Chunk 149: 这些ID应该是一个字符串，用于唯一标识每个用户。建议对其用户名或电子邮件地址进行哈希处理，以避免发送任何身份信息。如果向非登录用户提供产品预览，可以发送一个会话ID。\n",
      "可以通过 user 参数在API请求中包含终端用户ID，如下所示：\n",
      "response = openai.Completion.create(\n",
      "  model=\"text-davinci-003\",\n",
      "  prompt=\"This is a test\",\n",
      "  max_tokens=5,\n",
      "  user=\"user123456\"\n",
      ")\n",
      "Chunk 150: 最佳生产实践\n",
      "本指南提供了一套全面的最佳实践，可帮助您从原型过渡到生产。无论您是经验丰富的机器学习工程师还是新近的爱好者，本指南都将为您提供成功将平台投入生产环境所需的工具：从保护对我们API的访问到设计一个能够处理大流量的强大架构。使用本指南帮助您制定一个尽可能顺利和有效的应用程序部署计划。\n",
      "Chunk 151: 设置您的组织\n",
      "一旦您登录到OpenAI帐户，您可以在组织设置中找到组织名称和ID。组织名称是您的组织的标签，显示在用户界面中。组织ID是您的组织的唯一标识符，可用于API请求中。\n",
      "属于多个组织的用户可以传递一个标题来指定用于API请求的组织。这些API请求的使用将计入指定组织的配额。如果没有提供标题，则会计费默认组织。您可以在用户设置中更改默认组织。\n",
      "您可以从成员设置页面邀请新成员加入您的组织。成员可以是阅读者或所有者。阅读者可以进行API请求并查看基本组织信息，而所有者可以修改计费信息并管理组织中的成员。\n",
      "Chunk 152: 管理计费限额\n",
      "新的免费试用用户将获得5美元的初始信用额，有效期为三个月。一旦信用额已被使用或到期，您可以选择输入计费信息以继续使用API。如果没有输入计费信息，您仍然可以登录访问，但将无法进行任何进一步的API请求。\n",
      "一旦您输入了计费信息，您将获得OpenAI设置的每月120美元的批准使用限制。如果您想增加超过每月120美元的配额，请提交配额增加请求。\n",
      "Chunk 153: 一旦您输入了计费信息，您将获得OpenAI设置的每月120美元的批准使用限制。如果您想增加超过每月120美元的配额，请提交配额增加请求。\n",
      "如果您希望在使用量超过一定金额时收到通知，您可以通过使用限制页面设置软限制。当达到软限制时，组织的所有者将收到电子邮件通知。您还可以设置硬限制，以便一旦达到硬限制，任何后续的API请求都将被拒绝。请注意，这些限制是尽力而为，使用量和限制之间可能会有5到10分钟的延迟。\n",
      "Chunk 154: API密钥\n",
      "OpenAI API使用API密钥进行身份验证。访问您的API密钥页面以检索您将在请求中使用的API密钥。\n",
      "这是一种相对简单的控制访问方式，但您必须注意保护这些密钥。避免在您的代码或公共存储库中公开API密钥；相反，将它们存储在安全的位置。您应该使用环境变量或密钥管理服务将您的密钥暴露给您的应用程序，这样您就不需要在代码库中硬编码它们。\n",
      "Chunk 155: 暂存帐户\n",
      "随着规模的扩大，您可能希望为暂存和生产环境创建单独的组织。请注意，您可以使用两个单独的电子邮件地址（例如 [email protected] 和 [email protected]）进行注册，以创建两个组织。这将允许您隔离您的开发和测试工作，这样您就不会意外地中断您的实时应用程序。您还可以通过这种方式限制对生产组织的访问。\n",
      "Chunk 156: 扩展您的解决方案架构\n",
      "当设计你的应用程序或服务使用我们的API进行生产时，重要的是要考虑你将如何扩展以满足流量需求。无论你选择什么样的云服务提供商，你都需要考虑几个关键领域：\n",
      "横向扩展：你可能想横向扩展你的应用程序，以适应来自多个来源的应用程序的请求。这可能涉及到部署额外的服务器或容器来分配负载。如果你选择这种类型的扩展，请确保你的架构是为处理多个节点而设计的，并且你有机制来平衡它们之间的负载。\n",
      "Chunk 157: 当设计你的应用程序或服务使用我们的API进行生产时，重要的是要考虑你将如何扩展以满足流量需求。无论你选择什么样的云服务提供商，你都需要考虑几个关键领域：\n",
      "横向扩展：你可能想横向扩展你的应用程序，以适应来自多个来源的应用程序的请求。这可能涉及到部署额外的服务器或容器来分配负载。如果你选择这种类型的扩展，请确保你的架构是为处理多个节点而设计的，并且你有机制来平衡它们之间的负载。\n",
      "垂直扩展：另一个选择是纵向扩展你的应用程序，这意味着你可以加强单个节点的可用资源。这将涉及升级你的服务器的能力，以处理额外的负载。如果你选择这种类型的扩展，确保你的应用程序被设计成可以利用这些额外的资源。\n",
      "Chunk 158: 垂直扩展：另一个选择是纵向扩展你的应用程序，这意味着你可以加强单个节点的可用资源。这将涉及升级你的服务器的能力，以处理额外的负载。如果你选择这种类型的扩展，确保你的应用程序被设计成可以利用这些额外的资源。\n",
      "缓存：通过存储经常访问的数据，你可以提高响应时间，而不需要重复调用我们的API。你的应用程序将需要被设计成尽可能地使用缓存数据，并在添加新信息时使缓存失效。有几种不同的方法可以做到这一点。例如，你可以将数据存储在数据库、文件系统或内存缓存中，这取决于什么对你的应用程序最有意义。\n",
      "Chunk 159: 缓存：通过存储经常访问的数据，你可以提高响应时间，而不需要重复调用我们的API。你的应用程序将需要被设计成尽可能地使用缓存数据，并在添加新信息时使缓存失效。有几种不同的方法可以做到这一点。例如，你可以将数据存储在数据库、文件系统或内存缓存中，这取决于什么对你的应用程序最有意义。\n",
      "负载平衡：最后，考虑负载平衡技术，以确保请求被均匀地分布在你的可用服务器上。这可能涉及到在你的服务器前使用一个负载平衡器或使用DNS轮流。平衡负载将有助于提高性能和减少\n",
      "Chunk 160: 延迟\n",
      "延迟是处理请求和返回响应所需的时间，完成请求的延迟主要受两个因素影响：模型和生成的token数量。完成请求的生命周期如下所示（大部分延迟通常来自token生成步骤）：\n",
      "\n",
      "网络：最终用户到 API 延迟\n",
      "服务器：处理提示token的时间\n",
      "服务器：采样/生成to ken的时间\n",
      "网络：API 到最终用户延迟\n",
      "\n",
      "\n",
      "影响延迟的常见因素和可能的缓解技术\n",
      "现在我们已经了解了延迟的基础知识，让我们看一下可能影响延迟的各种因素，大致按照从影响最大到最小的顺序排列。\n",
      "Chunk 161: 影响延迟的常见因素和可能的缓解技术\n",
      "现在我们已经了解了延迟的基础知识，让我们看一下可能影响延迟的各种因素，大致按照从影响最大到最小的顺序排列。\n",
      "\n",
      "模型\n",
      "我们的 API 提供了不同程度的复杂性和通用性的不同模型。最有能力的模型，例如 gpt-4 ，可以生成更复杂和多样化的完成，但它们也需要更长的时间来处理您的查询。 gpt-3.5-turbo 等模型可以生成更快、更便宜的聊天完成，但它们生成的结果可能不太准确或与您的查询不相关。您可以选择最适合您的用例的模型以及速度和质量之间的权衡。\n",
      "\n",
      "补全token的数量\n",
      "请求大量生成的token完成会导致延迟增加：\n",
      "Chunk 162: 较低的最大token数：对于具有相似token生成计数的请求，具有较低 max_tokens 参数的请求会产生较少的延迟。\n",
      "包括停止序列：为防止生成不需要的token，请添加停止序列。例如，您可以使用停止序列生成包含特定数量项目的列表。在这种情况下，通过使用 11. 作为停止序列，您可以生成一个只有 10 个项目的列表，因为当到达 11. 时完成将停止。\n",
      "Chunk 163: 生成更少的完成：尽可能降低 n 和 best_of 的值，其中 n 是指为每个提示生成多少个完成， best_of 用于表示每个标记具有最高对数概率的结果。如果 n 和 best_of 都等于1（这是默认值），则生成的token数最多等于 max_tokens 。如果 n （返回的完成数）或 best_of （生成以供考虑的完成数）设置为 > 1 ，每个请求将创建多个输出。在这里，您可以将生成的token数视为 [ max_tokens * max (n, best_of) ]\n",
      "Chunk 164: 流式传输\n",
      "在请求中设置 stream: true 会使模型在token可用时立即开始返回token，而不是等待生成完整的token序列。它不会改变获取所有token的时间，但它会减少我们想要显示部分进度或将停止生成的应用程序的第一个token的时间。这可能是更好的用户体验和 UX 改进，因此值得尝试流式传输。\n",
      "Chunk 165: 批处理\n",
      "根据您的用例，批处理可能会有所帮助。如果您向同一个端点发送多个请求，您可以批处理要在同一个请求中发送的提示。这将减少您需要提出的请求数量。 prompt 参数最多可以包含 20 个不同的提示。我们建议您测试此方法，看看是否有帮助。在某些情况下，您最终可能会增加生成的token数量，这会减慢响应时间。\n",
      "\n",
      "\n",
      "\n",
      "MLOps策略\n",
      "当您将原型投入生产时，您可能需要考虑制定 MLOps 策略。 MLOps（机器学习操作）是指管理机器学习模型的端到端生命周期的过程，包括您可能使用我们的 API 进行微调的任何模型。设计 MLOps 策略时需要考虑多个方面。这些包括\n",
      "Chunk 166: MLOps策略\n",
      "当您将原型投入生产时，您可能需要考虑制定 MLOps 策略。 MLOps（机器学习操作）是指管理机器学习模型的端到端生命周期的过程，包括您可能使用我们的 API 进行微调的任何模型。设计 MLOps 策略时需要考虑多个方面。这些包括\n",
      "\n",
      "数据和模型管理：管理用于训练或微调模型以及跟踪版本和更改的数据。\n",
      "模型监控：随着时间的推移跟踪模型的性能并检测任何潜在的问题或退化。\n",
      "模型再训练：确保您的模型与数据变化或不断变化的需求保持同步，并根据需要进行再训练或微调。\n",
      "模型部署：自动化将模型和相关工件部署到生产中的过程。\n",
      "\n",
      "\n",
      "\n",
      "参考链接\n",
      "Chunk 167: 数据和模型管理：管理用于训练或微调模型以及跟踪版本和更改的数据。\n",
      "模型监控：随着时间的推移跟踪模型的性能并检测任何潜在的问题或退化。\n",
      "模型再训练：确保您的模型与数据变化或不断变化的需求保持同步，并根据需要进行再训练或微调。\n",
      "模型部署：自动化将模型和相关工件部署到生产中的过程。\n",
      "\n",
      "\n",
      "\n",
      "参考链接\n",
      "\n",
      "OpenAI 文档\n",
      "OpenAI Cookbook：分享了使用OpenAI API完成常见任务的示例代码\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " results matching \"\"\n",
      "\n",
      "\n",
      "\n",
      "No results matching \"\"\n"
     ]
    }
   ],
   "source": [
    "for i, d in enumerate(doc3):\n",
    "    print(f\"Chunk {i}: {d.page_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding documents 0 to 16\n",
      "Adding documents 16 to 32\n",
      "Adding documents 32 to 48\n",
      "Adding documents 48 to 64\n",
      "Adding documents 64 to 80\n",
      "Adding documents 80 to 96\n",
      "Adding documents 96 to 112\n",
      "Adding documents 112 to 128\n",
      "Adding documents 128 to 144\n",
      "Adding documents 144 to 160\n",
      "Adding documents 160 to 176\n",
      "Adding documents 176 to 192\n",
      "Adding documents 192 to 208\n",
      "Adding documents 208 to 224\n",
      "Adding documents 224 to 240\n",
      "Adding documents 240 to 256\n",
      "Adding documents 256 to 272\n",
      "Adding documents 272 to 288\n",
      "Adding documents 288 to 304\n",
      "Adding documents 304 to 320\n"
     ]
    }
   ],
   "source": [
    "from myqianfan import QianfanEmbedding\n",
    "vectorstore = Chroma(\"qianfan\", embedding_function=QianfanEmbedding(), persist_directory=\"vectorstore/qianfan.vec\")\n",
    "batch_size = 16\n",
    "doc_ids = []\n",
    "for i in range(0, len(splits), batch_size):\n",
    "    print(f\"Adding documents {i} to {i+batch_size}\")\n",
    "    texts = [doc.page_content for doc in splits[i:i+batch_size]]\n",
    "    metadatas = [doc.metadata for doc in splits[i:i+batch_size]]\n",
    "    doc_ids += vectorstore.add_texts(texts, metadatas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/langsmith/client.py:354: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n",
      "[WARNING][2024-10-14 23:40:08.501] base.py:916 [t:8703163072]: This key `disable_search` does not seem to be a parameter that the model `ERNIE-Tiny-8K` will accept\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'大语言模型的应用场景包括但不限于以下几个方面：\\n\\n1. 自然语言处理：用于文本生成、情感分析、机器翻译等任务。\\n2. 智能客服：能够提供智能化的客户服务，帮助回答用户的问题和提供解决方案。\\n3. 智能推荐系统：能够根据用户的兴趣和行为，提供个性化的产品和服务推荐。\\n4. 智能语音助手：可以应用于智能手机、智能家居等设备，帮助用户实现语音控制。\\n5. 科研领域：用于数据挖掘、机器学习、自然语言处理等领域的研究和应用。\\n\\n总的来说，大语言模型是一种强大的技术工具，具有广泛的应用前景。'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve and generate using the relevant snippets of the blog.\n",
    "retriever = vectorstore.as_retriever()\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain.invoke(\"大语言模型的应用场景有哪些？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING][2024-10-14 23:41:54.851] base.py:916 [t:8703163072]: This key `disable_search` does not seem to be a parameter that the model `ERNIE-Tiny-8K` will accept\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'掩码语言模型是一种训练方法，用于对输入文本中的词元进行掩码，基于上下文来预测被掩码的词元。BERT 是典型的掩码语言模型之一，具有在许多 NLP 任务中取得最佳表现的能力。它使用 Transformer 架构等技术，在大型文本语料上训练，并在自然语言处理领域中扮演重要角色。著名的掩码语言模型包括 BERT、RoBERTa 和 T5 等。这些模型在早期发展阶段需要基于具体下游任务的数据集进行微调。在 LLM 的早期发展阶段，BERT 主要用于自然语言理解任务，通过双向预训练语言模型和微调技术来提高模型的性能。'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"掩码语言模型\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING][2024-10-14 23:44:17.823] base.py:916 [t:8703163072]: This key `disable_search` does not seem to be a parameter that the model `ERNIE-Tiny-8K` will accept\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'使用OpenAI需要准备一些资料和工具，包括相关的许可证、开发环境、API密钥等，以及相关的技术文档和参考资料。具体来说，需要了解OpenAI的相关API和SDK，熟悉开发环境和技术要求，掌握相关的编程语言和工具，以及了解相关的安全性和隐私保护措施。同时，还需要对相关的法律法规和政策要求进行了解和遵守。'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"使用OpenAI需要准备什么\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': '你好, 世界上最大的动物是什么？'},\n",
       " {'role': 'assistant',\n",
       "  'content': '世界上最大的动物是鲸鱼。鲸鱼是一种大型海洋哺乳动物，属于鲸目。它们生活在海洋中，体型巨大，是已知动物中最大的种类之一。'},\n",
       " {'role': 'user',\n",
       "  'content': \"Human: You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: 大语言模型的应用场景有哪些？ \\nContext: 大语言模型概述\\n            \\n                \\n\\n\\n\\n            \\n                    \\n                    大语言模型概况\\n            \\n                \\n\\n\\n\\n            \\n                    \\n                    你好, ChatGPT\\n\\n大语言模型概述\\n            \\n                \\n\\n\\n\\n            \\n                    \\n                    大语言模型概况\\n            \\n                \\n\\n\\n\\n            \\n                    \\n                    你好, ChatGPT\\n\\n大语言模型概述\\n            \\n                \\n\\n\\n\\n            \\n                    \\n                    大语言模型概况\\n            \\n                \\n\\n\\n\\n            \\n                    \\n                    你好, ChatGPT\\n\\n关注《莫尔索随笔》\\n            \\n                \\n\\n\\n\\n            \\n                    \\n                    大语言模型概述\\n            \\n                \\n\\n\\n\\n            \\n                    \\n                    大语言模型概况 \\nAnswer:\"},\n",
       " {'role': 'assistant',\n",
       "  'content': '大语言模型的应用场景包括但不限于以下几个方面：\\n\\n1. 自然语言处理：用于文本生成、情感分析、机器翻译等任务。\\n2. 智能客服：能够提供智能化的客户服务，帮助回答用户的问题和提供解决方案。\\n3. 智能推荐系统：能够根据用户的兴趣和行为，提供个性化的产品和服务推荐。\\n4. 智能语音助手：可以应用于智能手机、智能家居等设备，帮助用户实现语音控制。\\n5. 科研领域：用于数据挖掘、机器学习、自然语言处理等领域的研究和应用。\\n\\n总的来说，大语言模型是一种强大的技术工具，具有广泛的应用前景。'},\n",
       " {'role': 'user',\n",
       "  'content': \"Human: You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: 掩码语言模型 \\nContext: 掩码模型：掩码语言模型(MLM)需要对输入文本中的一些词元进行掩码，然后训练模型基于上下文来预测被掩码的词元，例如输入句子“I love [MASK] learning”，输出“I love machine learning”，模型需要填充[MASK]来预测掩码词，实现对上下文的理解。BERT 就是一种典型的掩码语言模型。\\n\\n掩码语言模型是一种常用的训练方法，它基于上下文来预测句子中被遮掩的词，使得模型能够更深刻地理解词与其上下文之间的关系。这些模型使用 Transformer 架构等技术在大型文本语料上训练，并在许多 NLP 任务中取得了最佳表现，如情感分析和命名实体识别。著名的掩码语言模型有 BERT、RoBERTa 和 T5。由于其在多种任务上的成功表现，掩码语言模型已成为自然语言处理领域的一种重要工具，但这些方法需要基于具体下游任务的数据集进行微调。在 LLM 的早期发展阶段，BERT\\n\\nTransformer 架构等技术在大型文本语料上训练，并在许多 NLP 任务中取得了最佳表现，如情感分析和命名实体识别。著名的掩码语言模型有 BERT、RoBERTa 和 T5。由于其在多种任务上的成功表现，掩码语言模型已成为自然语言处理领域的一种重要工具，但这些方法需要基于具体下游任务的数据集进行微调。在 LLM 的早期发展阶段，BERT 为仅编码器模型带来了初始的爆发式增长。（BERT主要用于自然语言理解任务：双向预训练语言模型+fine-tuning（微调））\\n\\n基于大型语言模型的生成式AI\\n            \\n                \\n\\n\\n\\n            \\n                    \\n                    课程介绍\\n            \\n                \\n\\n\\n\\n\\n\\n            \\n                    \\n                    参考资料 \\nAnswer:\"},\n",
       " {'role': 'assistant',\n",
       "  'content': '掩码语言模型是一种训练方法，用于对输入文本中的词元进行掩码，基于上下文来预测被掩码的词元。BERT 是典型的掩码语言模型之一，具有在许多 NLP 任务中取得最佳表现的能力。它使用 Transformer 架构等技术，在大型文本语料上训练，并在自然语言处理领域中扮演重要角色。著名的掩码语言模型包括 BERT、RoBERTa 和 T5 等。这些模型在早期发展阶段需要基于具体下游任务的数据集进行微调。在 LLM 的早期发展阶段，BERT 主要用于自然语言理解任务，通过双向预训练语言模型和微调技术来提高模型的性能。'},\n",
       " {'role': 'user',\n",
       "  'content': \"Human: You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: 使用OpenAI需要准备什么 \\nContext: 基于 OpenAI API 搭建一个端到端问答系统\\n            \\n                \\n\\n\\n\\n            \\n                    \\n                    LLM 安全专题\\n\\n基于 OpenAI API 搭建一个端到端问答系统\\n            \\n                \\n\\n\\n\\n            \\n                    \\n                    LLM 安全专题\\n\\n基于 OpenAI API 搭建一个端到端问答系统\\n            \\n                \\n\\n\\n\\n            \\n                    \\n                    LLM 安全专题\\n\\n动手实现聊天机器人\\n            \\n                \\n\\n\\n\\n            \\n                    \\n                    基于 OpenAI API 搭建一个端到端问答系统 \\nAnswer:\"},\n",
       " {'role': 'assistant',\n",
       "  'content': '使用OpenAI需要准备一些资料和工具，包括相关的许可证、开发环境、API密钥等，以及相关的技术文档和参考资料。具体来说，需要了解OpenAI的相关API和SDK，熟悉开发环境和技术要求，掌握相关的编程语言和工具，以及了解相关的安全性和隐私保护措施。同时，还需要对相关的法律法规和政策要求进行了解和遵守。'}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.conversation_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING][2024-10-14 23:49:33.749] base.py:916 [t:8703163072]: This key `disable_search` does not seem to be a parameter that the model `ERNIE-Tiny-8K` will accept\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'根据提供的Context，Chat Completions会话补全是使用频次最高的接口之一，几乎所有套壳ChatGPT应用都基于这个接口。给定一组描述对话的消息列表，模型将返回一个回复，其中包含关于Chat Completions会话补全的详细信息。\\n\\n在给出的Context中，模型返回了一个关于ChatGPT的回复，并提供了OpenAI文档解读。你可以通过调用OpenAI API创建聊天机器人，并使用提供的消息列表来获取相应的回复。\\n\\n至于如何动手实现聊天机器人，这取决于你的具体需求和技能水平。你可以参考OpenAI的文档或相关教程，学习如何使用OpenAI API创建聊天机器人。同时，你也可以根据自己的创意和想法，编写相应的代码来实现聊天机器人。'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"Chat Completions 会话补全和响应\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-wechat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
