{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
      "[WARNING][2024-10-22 22:03:11.584] redis_rate_limiter.py:21 [t:8703163072]: no redis installed, RedisRateLimiter unavailable\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "from llmagent.privatestore import WebStore, WebConf\n",
    "from llmagent.llmapi import QianfanEmbedding\n",
    "from llmagent.secret import AK_SK\n",
    "keys = AK_SK('../llmagent/secret/keystore/qianfan.keys')\n",
    "os.environ[\"QIANFAN_ACCESS_KEY\"] = keys.get_ak()\n",
    "os.environ[\"QIANFAN_SECRET_KEY\"] = keys.get_sk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from llmagent.llmapi import QianfanLLM, QianfanEmbedding, model_spec\n",
    "\n",
    "# llm = QianfanLLM(model_spec=model_spec.Speed128K, temperature=0.5)\n",
    "embedding = QianfanEmbedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "webstore = WebStore(\"llmtutorial\", \"../vectorstore/llmtutorial\", emb_func=embedding, extra_config=WebConf(\n",
    "    root_url=\"https://aitutor.liduos.com/\",\n",
    "    # exclude_tags=['li'],\n",
    "    limit=10,\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WebConf(batch_size=16, chunk_size=300, chunk_overlap=100, root_url='https://aitutor.liduos.com/', exclude_tags=[], limit=10, header_template={}, verify_ssl=False, proxies=None, continue_on_failure=True, autoset_encoding=True, encoding=None, default_parser='html.parser', bs_kwargs=None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webstore._extra_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "webstore.del_docment(\"https://aitutor.liduos.com/01-llm/01-1.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'aitutor.liduos.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'aitutor.liduos.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "\u001b[32m2024-10-22 22:18:09.547\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mAdding documents 0 to 16\u001b[0m\n",
      "\u001b[32m2024-10-22 22:18:09.918\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mAdding documents 16 to 32\u001b[0m\n",
      "\u001b[32m2024-10-22 22:18:10.132\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mAdding documents 32 to 48\u001b[0m\n",
      "\u001b[32m2024-10-22 22:18:10.370\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mAdding documents 48 to 64\u001b[0m\n",
      "\u001b[32m2024-10-22 22:18:10.554\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mAdding documents 64 to 80\u001b[0m\n",
      "\u001b[32m2024-10-22 22:18:10.741\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mAdding documents 80 to 96\u001b[0m\n",
      "\u001b[32m2024-10-22 22:18:10.970\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mAdding documents 96 to 112\u001b[0m\n",
      "\u001b[32m2024-10-22 22:18:11.172\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mAdding documents 112 to 128\u001b[0m\n",
      "\u001b[32m2024-10-22 22:18:11.856\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mAdding documents 128 to 144\u001b[0m\n",
      "\u001b[32m2024-10-22 22:18:12.028\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mAdding documents 144 to 160\u001b[0m\n",
      "\u001b[32m2024-10-22 22:18:12.292\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mAdding documents 160 to 176\u001b[0m\n",
      "\u001b[32m2024-10-22 22:18:12.483\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mAdding documents 176 to 192\u001b[0m\n",
      "\u001b[32m2024-10-22 22:18:12.673\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mAdding documents 192 to 208\u001b[0m\n",
      "\u001b[32m2024-10-22 22:18:12.846\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mAdding documents 208 to 224\u001b[0m\n",
      "\u001b[32m2024-10-22 22:18:13.052\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mAdding documents 224 to 240\u001b[0m\n",
      "\u001b[32m2024-10-22 22:18:13.284\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mAdding documents 240 to 256\u001b[0m\n",
      "\u001b[32m2024-10-22 22:18:13.483\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mAdding documents 256 to 272\u001b[0m\n",
      "\u001b[32m2024-10-22 22:18:13.728\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mAdding documents 272 to 288\u001b[0m\n",
      "\u001b[32m2024-10-22 22:18:13.926\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mAdding documents 288 to 304\u001b[0m\n",
      "\u001b[32m2024-10-22 22:18:14.146\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mAdding documents 304 to 320\u001b[0m\n",
      "\u001b[32m2024-10-22 22:18:14.361\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mAdding documents 320 to 336\u001b[0m\n",
      "\u001b[32m2024-10-22 22:18:14.574\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mAdding documents 336 to 352\u001b[0m\n",
      "\u001b[32m2024-10-22 22:18:14.928\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mAdding documents 352 to 368\u001b[0m\n",
      "\u001b[32m2024-10-22 22:18:15.200\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mAdding documents 368 to 384\u001b[0m\n",
      "\u001b[32m2024-10-22 22:18:15.398\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mAdding documents 384 to 400\u001b[0m\n",
      "\u001b[32m2024-10-22 22:18:15.609\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mAdding documents 400 to 416\u001b[0m\n",
      "\u001b[32m2024-10-22 22:18:15.824\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mAdding documents 416 to 432\u001b[0m\n",
      "\u001b[32m2024-10-22 22:18:16.015\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mAdding documents 432 to 448\u001b[0m\n",
      "\u001b[32m2024-10-22 22:18:16.269\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mAdding documents 448 to 464\u001b[0m\n",
      "\u001b[32m2024-10-22 22:18:16.574\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mAdding documents 464 to 480\u001b[0m\n",
      "\u001b[32m2024-10-22 22:18:16.800\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mAdding documents 480 to 496\u001b[0m\n",
      "\u001b[32m2024-10-22 22:18:17.010\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mAdding documents 496 to 512\u001b[0m\n",
      "\u001b[32m2024-10-22 22:18:17.322\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mAdding documents 512 to 528\u001b[0m\n",
      "\u001b[32m2024-10-22 22:18:17.550\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mAdding documents 528 to 544\u001b[0m\n",
      "\u001b[32m2024-10-22 22:18:17.927\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mAdding documents 544 to 560\u001b[0m\n",
      "\u001b[32m2024-10-22 22:18:18.150\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mAdding documents 560 to 576\u001b[0m\n",
      "\u001b[32m2024-10-22 22:18:18.350\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mAdding documents 576 to 592\u001b[0m\n",
      "\u001b[32m2024-10-22 22:18:18.558\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mAdding documents 592 to 608\u001b[0m\n",
      "\u001b[32m2024-10-22 22:18:18.778\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mAdding documents 608 to 624\u001b[0m\n",
      "\u001b[32m2024-10-22 22:18:19.008\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mAdding documents 624 to 640\u001b[0m\n",
      "\u001b[32m2024-10-22 22:18:19.244\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mAdding documents 640 to 656\u001b[0m\n",
      "\u001b[32m2024-10-22 22:18:19.460\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mAdding documents 656 to 672\u001b[0m\n",
      "\u001b[32m2024-10-22 22:18:19.660\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mAdding documents 672 to 688\u001b[0m\n",
      "\u001b[32m2024-10-22 22:18:19.870\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mAdding documents 688 to 704\u001b[0m\n",
      "\u001b[32m2024-10-22 22:18:20.049\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mAdding documents 704 to 720\u001b[0m\n",
      "\u001b[32m2024-10-22 22:18:20.249\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mAdding documents 720 to 736\u001b[0m\n",
      "\u001b[32m2024-10-22 22:18:20.482\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mAdding documents 736 to 752\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "webstore.reload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1483"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webstore.collection_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Title    你好, ChatGPT (..)         本电子书开源，欢迎 star 🌟，关注《LLM 应用开发实践笔记》  我的新书 《LangChain编程从入门到实践》 (https://u.jd.com/V8pkqFY) 已经开售！推荐正在学习AI应用开发的朋友购买阅读！   你好, ChatGPT  ChatGPT 是OpenAI开发的人工智能聊天机器人程序，于2022年11月推出。该程序使用基于 GPT-3.5、GPT-4 架构的大语言模型并以强化学习训练。ChatGPT目前仍以文字方式交互，而除了可以用人类自然对话方式来交互，还可以用于甚为复杂的语言工作，包括自动生成文本、自动问答、自动摘要等多种任务。  ChatGPT的诞生  演进过程     总结    训练  训练有四个主要阶段：预训练、有监督微调、奖励建模、强化学习  Pretraining 预训练    Supervised Finetuning 监督微调    Reward Modeling 奖励建模    Reinforcement Learning 强化学习    特点    局限    参考链接        results matching \" \"     No results matching \" \"         (01-1.html)  (01-1.html)   (01-3.html)  (01-3.html)'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webstore._documents['https://aitutor.liduos.com/01-llm/01-2.html'].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system: This is the conversation so far:\n",
      "human: Hi, how are you?\n",
      "ai: I'm good, thanks! How can I help you today?\n",
      "human: Tell me a joke.\n",
      "ai: Why don't scientists trust atoms? Because they make up everything!\n",
      "human: Can you explain that joke?\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import HumanMessage, AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "# 感觉需要精简一下问题模版。现在llm中会自动记录之前的问答历史，但是如果增加了context，那么每次都需要api处理多个相同的context，感觉非常浪费\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"human\", \"你是一个解答用户问题的assistant，可以根据从语料库中召回的context文本回答问题。请尽量保证回答的内容都可以在context中找到根据，并务必保留 source 后面的url链接。\\n以下是context文本：{context}，\\n问题是：{question}\"),\n",
    "            (\"assistant\", \"根据context文本，我认为答案是：\"),\n",
    "        ]\n",
    "    )\n",
    "# 创建 ChatPromptTemplate，直接在模板中包含历史记录变量\n",
    "template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", \"This is the conversation so far:\\n{history}\"), (\"human\", \"{input}\")]\n",
    ")\n",
    "\n",
    "# 假设有一些聊天历史记录\n",
    "chat_history = [\n",
    "    HumanMessage(content=\"Hi, how are you?\"),\n",
    "    AIMessage(content=\"I'm good, thanks! How can I help you today?\"),\n",
    "    HumanMessage(content=\"Tell me a joke.\"),\n",
    "    AIMessage(content=\"Why don't scientists trust atoms? Because they make up everything!\")\n",
    "]\n",
    "\n",
    "# 将历史记录转换为字符串，控制需要传递的历史消息长度\n",
    "recent_history = \"\\n\".join([f\"{message.type}: {message.content}\" for message in chat_history])\n",
    "\n",
    "# 将裁剪后的历史和用户输入传递给模板\n",
    "prompt = template.format_messages(\n",
    "    history=recent_history,\n",
    "    input=\"Can you explain that joke?\"\n",
    ")\n",
    "\n",
    "for message in prompt:\n",
    "    print(f\"{message.type}: {message.content}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from urllib.parse import urljoin, urlparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://aitutor.liduos.com/\"\n",
    "\n",
    "# html_loader = AsyncHtmlLoader(web_path=url)\n",
    "# document = html_loader.load()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "# # def get_same_domain_links(url):\n",
    "#     # Load the webpage\n",
    "# loader = WebBaseLoader(url)\n",
    "# document = loader.load()[0] # 返回的是markdown格式的文档\n",
    "# url = \"https://aitutor.liduos.com/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterator\n",
    "from bs4 import BeautifulSoup\n",
    "from loguru import logger\n",
    "from langchain_community.document_transformers import BeautifulSoupTransformer\n",
    "\n",
    "def _build_metadata(soup, url: str) -> dict:\n",
    "    \"\"\"Build metadata from BeautifulSoup output.\"\"\"\n",
    "    metadata = {\"source\": url}\n",
    "    if title := soup.find(\"title\"):\n",
    "        metadata[\"title\"] = title.get_text()\n",
    "    if description := soup.find(\"meta\", attrs={\"name\": \"description\"}):\n",
    "        metadata[\"description\"] = description.get(\"content\", \"No description found.\")\n",
    "    if html := soup.find(\"html\"):\n",
    "        metadata[\"language\"] = html.get(\"lang\", \"No language found.\")\n",
    "    return metadata\n",
    "\n",
    "class WebRecursiveLoader(WebBaseLoader):\n",
    "    def __init__(self, root_url:str, depth: int = 1, unwanted_tags:List[str] = [], **kwargs):\n",
    "        super().__init__(web_path=root_url, **kwargs)\n",
    "        self.domain = urlparse(root_url).netloc\n",
    "        self.depth = depth\n",
    "        self.bs_transformer = BeautifulSoupTransformer()\n",
    "        self.unwanted_tags = list(set(unwanted_tags).union(set([\"script\", \"style\"])))\n",
    "\n",
    "    def lazy_load(self) -> Iterator[Document]:\n",
    "        loaded_set = set()\n",
    "        def __inner_load__(url: str, depth: int):\n",
    "            if depth < 0:\n",
    "                return\n",
    "            soup:BeautifulSoup = self._scrape(url, bs_kwargs=self.bs_kwargs)\n",
    "            # text = soup.get_text(**self.bs_get_text_kwargs)\n",
    "            text = str(soup)\n",
    "            metadata = _build_metadata(soup, url)\n",
    "            yield Document(page_content=text, metadata=metadata)\n",
    "            loaded_set.add(url)\n",
    "            links = soup.find_all(\"a\", href=True)\n",
    "            for link in links:\n",
    "                full_url = urljoin(url, link[\"href\"])\n",
    "                parsed_url = urlparse(full_url)\n",
    "                if parsed_url.netloc == self.domain and full_url not in loaded_set:\n",
    "                    yield from __inner_load__(full_url, depth - 1)\n",
    "        yield from __inner_load__(self.web_path, self.depth)\n",
    "    \n",
    "    def load(self) -> List[Document]:\n",
    "        return self.bs_transformer.transform_documents(list(self.lazy_load()), unwanted_tags=self.unwanted_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebRecursiveLoader(root_url=url, depth=2, unwanted_tags=[\"li\"], requests_per_second=10)\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Title    LlamaIndex介绍 (..)         本电子书开源，欢迎 star 🌟，关注《LLM 应用开发实践笔记》  我的新书 《LangChain编程从入门到实践》 (https://u.jd.com/V8pkqFY) 已经开售！推荐正在学习AI应用开发的朋友购买阅读！   LlamaIndex介绍  LlamaIndex(也称为GPT Index)是一个用户友好的接口，它将外部数据连接到大型语言模型(Large Language Models, llm)。它提供了一系列工具来简化流程，包括可以与各种现有数据源和格式(如api、pdf、文档和SQL)集成的数据连接器。此外，LlamaIndex为结构化和非结构化数据提供索引，可以毫不费力地与大语言模型一起使用。  包括列表索引、矢量存储索引、树索引和关键字表索引的分解，以及图索引、Pandas索引、SQL索引和文档摘要索引。  如果可用的tokens不多，则无法在prompt中输入更大的数据集，这可能会限制对模型的操作。使用LlamaIndex，可以为各种数据集(如文档、pdf和数据库)建立索引，然后轻松地查询它们以查找所需的信息。可以直接向知识库、Slack和其他通信工具以及数据库和几乎所有SaaS内容提出复杂的问题，而无需以任何特殊方式准备数据。       results matching \" \"     No results matching \" \"         (03-2.html)  (03-2.html)'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[14].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'https://aitutor.liduos.com/03-llamaIndex/03-1.html',\n",
       " 'title': 'LlamaIndex介绍 · LLM 应用开发实践笔记',\n",
       " 'description': '',\n",
       " 'language': 'zh-hans'}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[14].metadata"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-wechat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
