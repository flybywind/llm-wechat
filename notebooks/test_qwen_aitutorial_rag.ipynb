{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "from loguru import logger\n",
    "logger.remove()\n",
    "logger.add(sys.stdout, level=\"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.remove()\n",
    "logger.add(sys.stdout, level=\"DEBUG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "from llmagent.privatestore import WebStore, WebConf\n",
    "from llmagent.secret import AK_SK\n",
    "from llmagent.llmapi import model_spec, QwenEmbedding, QwenLLM\n",
    "qw_key = AK_SK(\"../llmagent/secret/keystore/qwen.keys\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = qw_key.ak\n",
    "llm = QwenLLM(model_spec=model_spec.QwenPlus, temperature=0.6)\n",
    "embedding = QwenEmbedding(api_key=qw_key.ak)\n",
    "webstore = WebStore(\"llmtutorial\", \"../vectorstore/llmtutorial_qwen\", emb_func=embedding, extra_config=WebConf(\n",
    "    root_url=\"https://aitutor.liduos.com/\",\n",
    "    limit=10,\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'aitutor.liduos.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'aitutor.liduos.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'aitutor.liduos.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'aitutor.liduos.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'aitutor.liduos.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'aitutor.liduos.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'aitutor.liduos.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'aitutor.liduos.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'aitutor.liduos.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'aitutor.liduos.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'aitutor.liduos.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'aitutor.liduos.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'aitutor.liduos.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'aitutor.liduos.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'aitutor.liduos.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'aitutor.liduos.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'aitutor.liduos.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'aitutor.liduos.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'aitutor.liduos.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'aitutor.liduos.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'aitutor.liduos.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'aitutor.liduos.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'aitutor.liduos.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'aitutor.liduos.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'aitutor.liduos.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'aitutor.liduos.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'aitutor.liduos.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'aitutor.liduos.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'aitutor.liduos.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'aitutor.liduos.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'aitutor.liduos.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'aitutor.liduos.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'aitutor.liduos.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'aitutor.liduos.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'aitutor.liduos.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'aitutor.liduos.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'aitutor.liduos.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'aitutor.liduos.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'aitutor.liduos.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'aitutor.liduos.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'aitutor.liduos.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'aitutor.liduos.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-10-25 09:26:35.931\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 0 to 16\u001b[0m\n",
      "\u001b[32m2024-10-25 09:26:36.704\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 16 to 32\u001b[0m\n",
      "\u001b[32m2024-10-25 09:26:37.485\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 32 to 48\u001b[0m\n",
      "\u001b[32m2024-10-25 09:26:38.262\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 48 to 64\u001b[0m\n",
      "\u001b[32m2024-10-25 09:26:38.943\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 64 to 80\u001b[0m\n",
      "\u001b[32m2024-10-25 09:26:39.674\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 80 to 96\u001b[0m\n",
      "\u001b[32m2024-10-25 09:26:40.390\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 96 to 112\u001b[0m\n",
      "\u001b[32m2024-10-25 09:26:41.295\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 112 to 128\u001b[0m\n",
      "\u001b[32m2024-10-25 09:26:42.228\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 128 to 144\u001b[0m\n",
      "\u001b[32m2024-10-25 09:26:42.932\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 144 to 160\u001b[0m\n",
      "\u001b[32m2024-10-25 09:26:43.756\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 160 to 176\u001b[0m\n",
      "\u001b[32m2024-10-25 09:26:44.557\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 176 to 192\u001b[0m\n",
      "\u001b[32m2024-10-25 09:26:45.295\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 192 to 208\u001b[0m\n",
      "\u001b[32m2024-10-25 09:26:46.361\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 208 to 224\u001b[0m\n",
      "\u001b[32m2024-10-25 09:26:47.174\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 224 to 240\u001b[0m\n",
      "\u001b[32m2024-10-25 09:26:47.838\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 240 to 256\u001b[0m\n",
      "\u001b[32m2024-10-25 09:26:48.528\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 256 to 272\u001b[0m\n",
      "\u001b[32m2024-10-25 09:26:49.481\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 272 to 288\u001b[0m\n",
      "\u001b[32m2024-10-25 09:26:50.303\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 288 to 304\u001b[0m\n",
      "\u001b[32m2024-10-25 09:26:51.054\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 304 to 320\u001b[0m\n",
      "\u001b[32m2024-10-25 09:26:51.851\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 320 to 336\u001b[0m\n",
      "\u001b[32m2024-10-25 09:26:52.511\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 336 to 352\u001b[0m\n",
      "\u001b[32m2024-10-25 09:26:53.229\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 352 to 368\u001b[0m\n",
      "\u001b[32m2024-10-25 09:26:54.204\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 368 to 384\u001b[0m\n",
      "\u001b[32m2024-10-25 09:26:55.027\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 384 to 400\u001b[0m\n",
      "\u001b[32m2024-10-25 09:26:56.054\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 400 to 416\u001b[0m\n",
      "\u001b[32m2024-10-25 09:26:56.898\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 416 to 432\u001b[0m\n",
      "\u001b[32m2024-10-25 09:26:57.585\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 432 to 448\u001b[0m\n",
      "\u001b[32m2024-10-25 09:26:58.560\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 448 to 464\u001b[0m\n",
      "\u001b[32m2024-10-25 09:26:59.272\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 464 to 480\u001b[0m\n",
      "\u001b[32m2024-10-25 09:27:00.127\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 480 to 496\u001b[0m\n",
      "\u001b[32m2024-10-25 09:27:00.858\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 496 to 512\u001b[0m\n",
      "\u001b[32m2024-10-25 09:27:01.534\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 512 to 528\u001b[0m\n",
      "\u001b[32m2024-10-25 09:27:02.428\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 528 to 544\u001b[0m\n",
      "\u001b[32m2024-10-25 09:27:03.117\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 544 to 560\u001b[0m\n",
      "\u001b[32m2024-10-25 09:27:03.987\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 560 to 576\u001b[0m\n",
      "\u001b[32m2024-10-25 09:27:04.758\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 576 to 592\u001b[0m\n",
      "\u001b[32m2024-10-25 09:27:05.430\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 592 to 608\u001b[0m\n",
      "\u001b[32m2024-10-25 09:27:06.203\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 608 to 624\u001b[0m\n",
      "\u001b[32m2024-10-25 09:27:06.992\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 624 to 640\u001b[0m\n",
      "\u001b[32m2024-10-25 09:27:07.733\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 640 to 656\u001b[0m\n",
      "\u001b[32m2024-10-25 09:27:08.434\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 656 to 672\u001b[0m\n",
      "\u001b[32m2024-10-25 09:27:09.147\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 672 to 688\u001b[0m\n",
      "\u001b[32m2024-10-25 09:27:09.873\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 688 to 704\u001b[0m\n",
      "\u001b[32m2024-10-25 09:27:10.803\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 704 to 720\u001b[0m\n",
      "\u001b[32m2024-10-25 09:27:11.811\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 720 to 736\u001b[0m\n",
      "\u001b[32m2024-10-25 09:27:12.636\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 736 to 752\u001b[0m\n",
      "\u001b[32m2024-10-25 09:27:13.400\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 752 to 768\u001b[0m\n",
      "\u001b[32m2024-10-25 09:27:14.211\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 768 to 784\u001b[0m\n",
      "\u001b[32m2024-10-25 09:27:15.084\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 784 to 800\u001b[0m\n",
      "\u001b[32m2024-10-25 09:27:15.969\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 800 to 816\u001b[0m\n",
      "\u001b[32m2024-10-25 09:27:16.914\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 816 to 832\u001b[0m\n",
      "\u001b[32m2024-10-25 09:27:17.799\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 832 to 848\u001b[0m\n",
      "\u001b[32m2024-10-25 09:27:18.646\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 848 to 864\u001b[0m\n",
      "\u001b[32m2024-10-25 09:27:19.790\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 864 to 880\u001b[0m\n",
      "\u001b[32m2024-10-25 09:27:21.126\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 880 to 896\u001b[0m\n",
      "\u001b[32m2024-10-25 09:27:22.017\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 896 to 912\u001b[0m\n",
      "\u001b[32m2024-10-25 09:27:23.492\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 912 to 928\u001b[0m\n",
      "\u001b[32m2024-10-25 09:27:24.595\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 928 to 944\u001b[0m\n",
      "\u001b[32m2024-10-25 09:27:25.306\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 944 to 960\u001b[0m\n",
      "\u001b[32m2024-10-25 09:27:26.014\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 960 to 976\u001b[0m\n",
      "\u001b[32m2024-10-25 09:27:26.853\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 976 to 992\u001b[0m\n",
      "\u001b[32m2024-10-25 09:27:27.532\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 992 to 1008\u001b[0m\n",
      "\u001b[32m2024-10-25 09:27:28.364\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 1008 to 1024\u001b[0m\n",
      "\u001b[32m2024-10-25 09:27:29.247\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 1024 to 1040\u001b[0m\n",
      "\u001b[32m2024-10-25 09:27:29.916\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 1040 to 1056\u001b[0m\n",
      "\u001b[32m2024-10-25 09:27:30.797\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 1056 to 1072\u001b[0m\n",
      "\u001b[32m2024-10-25 09:27:31.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 1072 to 1088\u001b[0m\n",
      "\u001b[32m2024-10-25 09:27:32.618\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 1088 to 1104\u001b[0m\n",
      "\u001b[32m2024-10-25 09:27:33.799\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 1104 to 1120\u001b[0m\n",
      "\u001b[32m2024-10-25 09:27:34.564\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 1120 to 1136\u001b[0m\n",
      "\u001b[32m2024-10-25 09:27:35.667\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 1136 to 1152\u001b[0m\n",
      "\u001b[32m2024-10-25 09:27:36.437\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 1152 to 1168\u001b[0m\n",
      "\u001b[32m2024-10-25 09:27:37.654\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 1168 to 1184\u001b[0m\n",
      "\u001b[32m2024-10-25 09:27:38.472\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 1184 to 1200\u001b[0m\n",
      "\u001b[32m2024-10-25 09:27:39.326\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 1200 to 1216\u001b[0m\n",
      "\u001b[32m2024-10-25 09:27:40.261\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 1216 to 1232\u001b[0m\n",
      "\u001b[32m2024-10-25 09:27:41.307\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 1232 to 1248\u001b[0m\n",
      "\u001b[32m2024-10-25 09:27:42.093\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 1248 to 1264\u001b[0m\n",
      "\u001b[32m2024-10-25 09:27:42.927\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 1264 to 1280\u001b[0m\n",
      "\u001b[32m2024-10-25 09:27:43.628\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 1280 to 1296\u001b[0m\n",
      "\u001b[32m2024-10-25 09:27:44.483\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 1296 to 1312\u001b[0m\n",
      "\u001b[32m2024-10-25 09:27:45.390\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 1312 to 1328\u001b[0m\n",
      "\u001b[32m2024-10-25 09:27:46.431\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 1328 to 1344\u001b[0m\n",
      "\u001b[32m2024-10-25 09:27:47.554\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 1344 to 1360\u001b[0m\n",
      "\u001b[32m2024-10-25 09:27:48.262\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 1360 to 1376\u001b[0m\n",
      "\u001b[32m2024-10-25 09:27:49.009\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 1376 to 1392\u001b[0m\n",
      "\u001b[32m2024-10-25 09:27:49.732\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mllmagent.privatestore.base\u001b[0m:\u001b[36m__load__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mAdding documents 1392 to 1408\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "webstore.reload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1393"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webstore.collection_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'作者：莫尔索 (https://liduos.com/about)     前言 (../)    关注《莫尔索随笔》 (https://liduos.com/wxqcode.png)    大语言模型概述    大语言模型概况 (01-1.html)    你好, ChatGPT (01-2.html)    OpenAI 文档解读 (01-3.html)    动手实现聊天机器人 (01-4.html)    基于 OpenAI API 搭建一个端到端问答系统 (01-5.html)    LLM 安全专题 (01-6.html)      LangChain入门    LangChain介绍 (../02-langchain/02-1.html)    LangChain模块学习 (../02-langchain/02-2.html)    LangChain之Chains模块 (../02-langchain/02-2-1.html)    LangChain之Agents模块 (../02-langchain/02-2-2.html)    LangChain之Callback模块 (../02-langchain/02-2-3.html)    Embedding嵌入 (../02-langchain/02-3.html)    动手实现文档问答机器人 (../02-langchain/02-4.html)      LlamaIndex 概述    LlamaIndex介绍 (../03-llamaIndex/03-1.html)    LlamaIndex索引 (../03-llamaIndex/03-2.html)    动手实现企业知识库 (../03-llamaIndex/03-3.html)      HuggingGPT 实现    HuggingFace 介绍 (../04-huggingface/04-1.html)    transformers 库基础组件 (../04-huggingface/04-2.html)    多模态任务设计 (../04-huggingface/04-3.html)    动手实现 HuggingGPT (../04-huggingface/04-4.html)      LLMOps 专题    LLMOps 介绍 (../06-llmops/06-1.html)    Model 模型层 (../06-llmops/06-2.html)    Prompt 提示层 (../06-llmops/06-3.html)    狭义LLMOps (../06-llmops/06-4.html)      Agent 专题    Agent 介绍 (../07-agents/07-1.html)    Agent 项目跟踪 (../07-agents/07-2.html)    Multi-Agent 系统 (../07-agents/07-3.html)      RAG专题    数据索引环节 (../08-rag/08-1.html)    检索环节 (../08-rag/08-2.html)    生成环节 (../08-rag/08-3.html)      LLM 应用评估与测试    如何评估一个大语言模型 (../09-llm-evelation-test/09-1.html)    基于大模型的Agent进行测试评估 (../09-llm-evelation-test/09-2.html)    RAG系统效果评估 (../09-llm-evelation-test/09-3.html)      国内模型厂商API解读    六家大模型能力比较 (../10-china-llm/10-01.html)    MiniMax大模型开发 (../10-china-llm/10-02.html)    智谱AI大模型开发 (../10-china-llm/10-03.html)    MoonShot大模型开发 (../10-china-llm/10-04.html)      基于大型语言模型的生成式AI    课程介绍 (../05-generative-ai-with-llms/05-1.html)      参考资料    A16Z推荐的AI学习清单 (../ref/a16z.html)    Prompt专题 (../ref/prompt.html)    一些课程资料汇总 (../ref/ref.html)       本书使用 GitBook 发布 (https://www.gitbook.com)         Title    你好, ChatGPT (..)         本电子书开源，欢迎 star 🌟，关注《LLM 应用开发实践笔记》  我的新书 《LangChain编程从入门到实践》 (https://u.jd.com/V8pkqFY) 已经开售！推荐正在学习AI应用开发的朋友购买阅读！   你好, ChatGPT  ChatGPT 是OpenAI开发的人工智能聊天机器人程序，于2022年11月推出。该程序使用基于 GPT-3.5、GPT-4 架构的大语言模型并以强化学习训练。ChatGPT目前仍以文字方式交互，而除了可以用人类自然对话方式来交互，还可以用于甚为复杂的语言工作，包括自动生成文本、自动问答、自动摘要等多种任务。  ChatGPT的诞生  演进过程   在 2020 年 7 月 ，OpenAI 发布了模型名称为的 davinci 的初代 GPT-3  在 2021 年 7 月 ，Codex 的论文发布，其中初始的 Codex 是根据 120 亿参数的 GPT-3 变体进行微调的。后来这个 120 亿参数的模型演变成 OpenAI API 中的 code-cushman-001  在 2022 年 3 月 ，OpenAI 发布了指令微调 (instruction tuning) 的论文，其监督微调 (supervised instruction tuning) 的部分对应了 davinci-instruct-beta 和 text-davinci-001  在 2022 年 4 月至 7 月的 ，OpenAI 开始对 code-davinci-002 模型进行 Beta 测试，也称其为 Codex   text-davinci-002 、 text-davinci-003 和 ChatGPT 都是从 code-davinci-002 进行指令微调得到的。详细信息请参阅 OpenAI的模型索引文档 (https://platform.openai.com/docs/model-index-for-researchers)   2022 年 5-6 月 发布的 text-davinci-002 是一个基于 code-davinci-002 的有监督指令微调 (supervised instruction tuned) 模型。在 text-davinci-002 上面进行 指令微调 很可能降低了模型的上下文学习能力，但是增强了模型的零样本能力。  text-davinci-003 和 ChatGPT ，它们都在 2022 年 11 月 发布，是使用的基于人类反馈的强化学习的版本指令微调 (instruction tuning with reinforcement learning from human feedback) 模型的两种不同变体。 text-davinci-003 恢复了（但仍然比 code-davinci-002 差）一些在 text-davinci-002 中丢失的部分上下文学习能力，并进一步改进了零样本能力（得益于RLHF）。另一方面，ChatGPT 似乎牺牲了几乎所有的上下文学习的能力来换取建模对话历史的能力。    总结   语言生成能力 + 基础世界知识 + 上下文学习都是来自于预训练（ davinci ）  存储大量知识的能力来自 1750 亿的参数量  遵循指令和泛化到新任务的能力来自于扩大指令学习中指令的数量（ davinci-instruct-beta ）  执行复杂推理的能力很可能来自于代码训练（ code-davinci-002 ）  生成中立、客观的能力、安全和翔实的答案来自与人类的对齐。具体来说：  如果是监督学习版，得到的模型是 text-davinci-002  如果是强化学习版 (RLHF) ，得到的模型是 text-davinci-003  无论是有监督还是 RLHF ，模型在很多任务的性能都无法超过 code-davinci-002 ，这种因为对齐而造成性能衰退的现象叫做对齐税。    对话能力也来自于 RLHF（ ChatGPT ），具体来说它牺牲了上下文学习的能力，来换取：  建模对话历史  增加对话信息量  拒绝模型知识范围之外的问题     训练  训练有四个主要阶段：预训练、有监督微调、奖励建模、强化学习  Pretraining 预训练   数据收集：CommonCrawl，C4也是common crawl，然后还有一些高质量的数据集，例如GitHub、维基百科、书籍、ArXiv论文存档、StackExchange问答网站等，这些都混合在一起，然后根据给定的比例进行采样。  标记化（tokenization）：标记化是文本片段和标记与整数之间的一种无损转换，是将互联网上抓取的原始文本翻译成整数序列。  训练过程，可以查观看这个视频进行了解 (https://www.bilibili.com/video/BV1ts4y1T7UH/?share_source=copy_web&vd_source=0b5a0297824b7741bbe169c01f734989&t=353)   Supervised Finetuning 监督微调   假设已经有了一个非常聪明的学生（即GPT-3模型），他已经学会了很多知识，并且可以在各种不同的主题上写文章。但是想让他专注于某个特定的主题，并且写出更好的文章。这就需要使用监督微调技术来让他集中精力并提高他在这个特定主题上的表现。  可以使用一个新的数据集来让这个学生熟悉这个领域的特定要求。例如为他提供一些示例文章，这些文章符合这个领域的要求，并让他通过学习这些文章来了解这个领域的特点和要求。这就像在学习一门新的科目时，我们需要先了解这门科目的基本概念和原理，然后通过实践来巩固这些知识。  一旦这位学生掌握了这个领域的基础知识，就可以开始进行实践并进行监督微调。可以让他写一些文章，并根据这些文章的质量来指导他的学习和进一步的改进。这就像在学习一门新的科目时，需要不断地进行实践和练习，以巩固我们的知识并提高我们的技能水平。最终，通过不断的实践和练习，这位学生将能够在这个特定的领域中表现出色，并写出符合要求的文章。   Reward Modeling 奖励建模   将奖励建模类比为让聪明的学生（即GPT-3模型）学习一门新的技能，例如学习打篮球。在学习打篮球的过程中，可以将得分作为奖励信号，以评估学生的表现。首先需要告诉学生如何打篮球，例如传球、投篮、防守等基本技能。这就像在奖励建模中，我们需要提供一些示例，以便模型可以了解任务的要求。  然后可以让学生在训练场上进行练习，并根据他们的表现来给予奖励。例如，如果学生成功投篮得分，我们可以给予他们一定的奖励分数。这就像在奖励建模中，可以根据模型的表现来生成奖励信号。如果模型成功完成任务，例如正确地回答问题或生成准确的文本，可以给予它一定的奖励分数。  通过不断的练习和奖励，学生将学会如何打篮球，并且在比赛中表现出色。同样地，通过奖励建模技术，我们可以训练GPT-3模型在特定任务中表现出色，并生成符合要求的文本。通过最大化奖励信号，模型可以学习如何有效地完成任务，并不断改进自己的表现。   Reinforcement Learning 强化学习   奖励建模的例子中，将奖励信号定义为每次得分的分数。如果聪明的学生成功地将篮球投入篮筐，给予它一定数量的分数；如果它没有得分，那么不给予它分数。在奖励建模中，可以使用这些分数作为奖励信号，来训练模型。我们的目标是最大化总得分，因为总得分是我们想要优化的目标函数。  强化学习中需要定义状态空间、行动空间和奖励函数，以让聪明的学生了解任务的要求。状态空间可以包括学生的位置、篮球的位置和篮筐的位置等信息，行动空间可以包括传球、投篮、防守等动作，奖励函数可以根据得分、失误、防守成功等情况来定义。然后让聪明的学生与环境交互，并根据当前状态和策略采取行动，并从环境中获得奖励或惩罚信号，聪明的学生可以不断更新策略，以最大化长期奖励，即总得分。  奖励建模使用奖励信号来指导模型的优化方向，而强化学习使用奖励信号来指导模型的行动选择。   特点   作为辅助工具，并与人工监督结合起来，在不注重可靠性和安全性的应用程序中使用  可以编写和调试计算机程序  具备创作音乐、电视剧、童话故事和学生论文的能力  ChatGPT 能够记住与用户之前的对话内容和给它的提示  可以回答测试问题（在某些测试情境下，水平甚至高于普通人类测试者）  ChatGPT 输入内容会由审核API过滤，以减少生成冒犯言论   局限   人工智能幻觉 (https://zh.wikipedia.org/zh-sg/%E5%B9%BB%E8%A7%89_%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD) ：有时会写出看似合理但不正确或荒谬的答案  古德哈特定律 (https://zh.wikipedia.org/zh-sg/%E5%8F%A4%E5%BE%B7%E5%93%88%E7%89%B9%E5%AE%9A%E5%BE%8B) ：奖励模型围绕人类监督而设计，可能导致过度优化，从而影响性能  意识形态偏见：研究表明，ChatGPT对两个投票建议应用程序的政治声明表明立场时，表现出亲环境主义。   参考链接   对GPT系列模型能力的溯源 (https://yaofu.notion.site/How-does-GPT-Obtain-its-Ability-Tracing-Emergent-Abilities-of-Language-Models-to-their-Sources-b9a57ac0fcf74f30a1ab9e3e36fa1dc1) ：详细分析OpenAI各个模型的演进关系，对理解OpenAI中各个模型API能力及ChatGPT发展历史很有帮助  State of GPT (https://build.microsoft.com/en-US/sessions/db3f4859-cd30-4445-a0cd-553c3304f8e2) ：大神Andrej揭秘OpenAI大模型原理和训练过程  ChatGPT (https://zh.wikipedia.org/zh-sg/ChatGPT#cite_note-CNNInfo-29) ：维基百科ChatGPT词条       results matching \" \"     No results matching \" \"         (01-1.html)  (01-1.html)   (01-3.html)  (01-3.html)'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webstore._documents['https://aitutor.liduos.com/01-llm/01-2.html'].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmagent.chain import QAWithContextChain, TemplateConf\n",
    "prompt = QAWithContextChain(llm=llm, \n",
    "                               vectorstore=webstore.vectorstore(),\n",
    "                               conf=TemplateConf(context_num=10, history_num=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-10-25 09:37:48.101\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mllmagent.llmapi.llm\u001b[0m:\u001b[36mstream\u001b[0m:\u001b[36m111\u001b[0m - \u001b[34m\u001b[1minput: [SystemMessage(content='你是一个解答用户问题的assistant，可以根据context资料回答问题。请尽量保证回答的内容都可以在context中找到根据，并务必保留资料最后的 source。以下是context资料：\\nTitle    LLM 安全专题 (..)         本电子书开源，欢迎 star 🌟，关注《LLM 应用开发实践笔记》  我的新书 《LangChain编程从入门到实践》 (https://u.jd.com/V8pkqFY) 已经开售！推荐正在学习AI应用开发的朋友购买阅读！   LLM 安全专题  提示词 是指在训练或与大型语言模型（Claude，ChatGPT等）进行交互时，提供给模型的输入文本。通过给定特定的 提示词，可以引导模型生成特定主题或类型的文本。在自然语言处理（NLP）任务中，提示词充当了问题或输入的角色，而模型的输出是对这个问题的回答或完成的任务。\\nsource: https://aitutor.liduos.com/01-llm/01-6.html\\n\\n提示词管理   提示模板 动态提示词=提示模板+变量，通过引入给提示词引入变量的方式，一方面保证了灵活性，一方面又能保证Prompt内容结构达到最佳   from langchain import PromptTemplate no_input_prompt = PromptTemplate(input_variables=[], template= \"Tell me a joke.\" ) no_input_prompt.format() one_input_prompt = PromptTemplate(input_variables=[ \"adjective\" ], template=\\nsource: https://aitutor.liduos.com/02-langchain/02-2.html\\n\\nModel I/O (https://python.langchain.com/docs/modules/model_io/)  这部分包括对大语言模型输入输出的管理，输入环节的提示词管理（包含模板化提示词和提示词动态选择等），处理环节的语言模型（包括所有LLMs的通用接口，以及常用的LLMs工具；Chat模型是一种与LLMs不同的API，用来处理消息），输出环节包括从模型输出中提取信息。   提示词管理   提示模板 动态提示词=提示模板+变量，通过引入给提示词引入变量的方式，一方面保证了灵活性，一方面又能保证Prompt内容结构达到最佳   from langchain import\\nsource: https://aitutor.liduos.com/02-langchain/02-2.html\\n\\n提示词，可以引导模型生成特定主题或类型的文本。在自然语言处理（NLP）任务中，提示词充当了问题或输入的角色，而模型的输出是对这个问题的回答或完成的任务。  关于怎样设计好的 Prompt，查看 Prompt专题 (../ref/prompt.html) 章节内容就可以了，我不在这里过多阐述，个人比较感兴趣针对 Prompt的攻击，随着大语言模型的广泛应用，安全必定是一个非常值得关注的领域。  提示攻击  提示攻击是一种利用 LLM\\nsource: https://aitutor.liduos.com/01-llm/01-6.html\\n\\n将Prompt输入与特征存储关联起来(FeaturePromptTemplate)  少样本提示模板（FewShotPromptTemplate）  从示例中动态提取提示词✍️     LLMs   LLMs  将文本字符串作为输入并返回文本字符串的模型（纯文本补全模型），这里重点说下做项目尽量用异步的方式，体验会更好，下面的例子连续10个请求，时间相差接近5s。   import time import asyncio from langchain.llms import OpenAI def  generate_serially () : llm =\\nsource: https://aitutor.liduos.com/02-langchain/02-2.html\\n\\n：可以套框架实现自己任何想要能力的 Prompt。  提示词工程指南 (https://www.promptingguide.ai/zh)  Learning Prompt (https://learnprompting.org/zh-Hans/docs/intro) ：Prompt Engineering超全教程，和落地应用收藏，包括很多LLM调用Agent的高级场景   中文提示词指南   个人翻译整理自仓库 awesome-chatgpt-prompts Public (https://github.com/f/awesome-chatgpt-prompts) ，可以应付 90%\\nsource: https://aitutor.liduos.com/ref/prompt.html\\n\\n推荐的Prompt学习资料   Prompt提示词课程 (https://www.bilibili.com/video/BV1Bo4y1A7FU) ：斯坦福吴恩达教授和 OpenAI 官方联合出品的ChatGPT Prompt提示词课程，质量很高的教学视频。  两个提示词框架 (https://www.zhihu.com/question/570765297/answer/2977526744) ：可以套框架实现自己任何想要能力的 Prompt。  提示词工程指南 (https://www.promptingguide.ai/zh)  Learning Prompt\\nsource: https://aitutor.liduos.com/ref/prompt.html\\n\\n：对于任何编写LLM提示的人——包括应用开发者——这是最全面的指南，对一些流行模型提供了具体示例。如果想要更轻松、更富有对话性的处理，可以尝试阅读 Brex的提示工程指南 (https://github.com/brexhq/prompt-engineering) 。  Prompt injection: What’s the worst that can happen? (https://simonwillison.net/2023/Apr/14/worst-that-can-happen/)\\nsource: https://aitutor.liduos.com/ref/a16z.html\\n\\n为了节省你的token，还可以在测试过程中使用一个模拟LLM输出的 FakeListLLM ；还有一个模拟用户输入的 HumanInputLLM 。  与其他 AI相关基础设施的 集成 (https://python.langchain.com/docs/modules/model_io/models/llms/integrations/ai21) ，用到随时查询即可     输出解析器  输出解析器用于构造大语言模型的响应格式，具体通过格式化指令和自定义方法两种方式。  # 格式化指令的方式  from langchain.output_parsers import\\nsource: https://aitutor.liduos.com/02-langchain/02-2.html\\n\\n《LangChain编程从入门到实践》 (https://u.jd.com/V8pkqFY) 已经开售！推荐正在学习AI应用开发的朋友购买阅读！   LangChain模块之 Callbacks (https://python.langchain.com/docs/modules/callbacks/)  回调模块允许接到LLM应用程序的各个阶段，鉴于LLM的幻觉问题，这对于日志记录、监视、流式处理和其他任务非常有用，现在也有专用的工具Helicone，Arize AI等产品可用，具体看 LLM应用生态初创公司说明 (../ref/company.md)  自定义回调对象\\nsource: https://aitutor.liduos.com/02-langchain/02-2-3.html，\\n以下是之前的聊天历史：\\n', additional_kwargs={}, response_metadata={}), HumanMessage(content='问题：langchain提示词管理', additional_kwargs={}, response_metadata={})]\u001b[0m\n",
      "\u001b[32m2024-10-25 09:37:48.163\u001b[0m | \u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36mllmagent.chain.base\u001b[0m:\u001b[36mstream\u001b[0m:\u001b[36m68\u001b[0m - \u001b[31m\u001b[1mError code: 400 - {'error': {'code': None, 'param': None, 'message': \"null is not one of ['system', 'assistant', 'user', 'tool', 'function'] - 'messages.['0].role'\", 'type': 'invalid_request_error'}}\u001b[0m\n",
      "\u001b[33m\u001b[1mTraceback (most recent call last):\u001b[0m\n",
      "\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "    │   └ <bound method Application.launch_instance of <class 'ipykernel.kernelapp.IPKernelApp'>>\n",
      "    └ <module 'ipykernel.kernelapp' from '/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/ipykernel/ker...\n",
      "  File \"/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "    │   └ <function IPKernelApp.start at 0x1058d5260>\n",
      "    └ <ipykernel.kernelapp.IPKernelApp object at 0x100dc8510>\n",
      "  File \"/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "    │    │       └ <function BaseAsyncIOLoop.start at 0x1058d6340>\n",
      "    │    └ <tornado.platform.asyncio.AsyncIOMainLoop object at 0x1058e6550>\n",
      "    └ <ipykernel.kernelapp.IPKernelApp object at 0x100dc8510>\n",
      "  File \"/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "    │    │            └ <function BaseEventLoop.run_forever at 0x102354b80>\n",
      "    │    └ <_UnixSelectorEventLoop running=True closed=False debug=False>\n",
      "    └ <tornado.platform.asyncio.AsyncIOMainLoop object at 0x1058e6550>\n",
      "  File \"/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "    │    └ <function BaseEventLoop._run_once at 0x102356980>\n",
      "    └ <_UnixSelectorEventLoop running=True closed=False debug=False>\n",
      "  File \"/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "    │      └ <function Handle._run at 0x1022eefc0>\n",
      "    └ <Handle Task.task_wakeup(<Future finis...490>, ...],))>)>\n",
      "  File \"/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "    │    │            │    │           │    └ <member '_args' of 'Handle' objects>\n",
      "    │    │            │    │           └ <Handle Task.task_wakeup(<Future finis...490>, ...],))>)>\n",
      "    │    │            │    └ <member '_callback' of 'Handle' objects>\n",
      "    │    │            └ <Handle Task.task_wakeup(<Future finis...490>, ...],))>)>\n",
      "    │    └ <member '_context' of 'Handle' objects>\n",
      "    └ <Handle Task.task_wakeup(<Future finis...490>, ...],))>)>\n",
      "  File \"/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "          │    └ <function Kernel.process_one at 0x10588e3e0>\n",
      "          └ <ipykernel.ipkernel.IPythonKernel object at 0x1058fa890>\n",
      "  File \"/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "          │         └ ([<zmq.sugar.frame.Frame object at 0x106a34dd0>, <zmq.sugar.frame.Frame object at 0x106a34e90>, <zmq.sugar.frame.Frame object...\n",
      "          └ <bound method Kernel.dispatch_shell of <ipykernel.ipkernel.IPythonKernel object at 0x1058fa890>>\n",
      "  File \"/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "          └ <coroutine object IPythonKernel.execute_request at 0x137b96140>\n",
      "  File \"/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "                                  │       │      └ {'header': {'date': datetime.datetime(2024, 10, 25, 1, 37, 47, 756000, tzinfo=tzutc()), 'msg_id': '5b8129c6-2649-4068-9909-49...\n",
      "                                  │       └ [b'4c81e0d1-802d-4459-960f-e4c5eb3f0780']\n",
      "                                  └ <zmq.eventloop.zmqstream.ZMQStream object at 0x1058e6850>\n",
      "  File \"/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "                          └ <coroutine object IPythonKernel.do_execute at 0x127e74cc0>\n",
      "  File \"/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "          │     └ <function ZMQInteractiveShell.run_cell at 0x1058c2340>\n",
      "          └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x1069ee210>\n",
      "  File \"/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "                             │       └ {'store_history': True, 'silent': False, 'cell_id': 'vscode-notebook-cell:/Users/flybywindwen/Projects/llm-wechat/notebooks/t...\n",
      "                             └ ('import time\\nans = prompt.stream(\"langchain提示词管理\")\\nfor token in ans:\\n    for c in token:\\n        time.sleep(0.1)\\n      ...\n",
      "  File \"/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "             │    └ <function InteractiveShell._run_cell at 0x103e29b20>\n",
      "             └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x1069ee210>\n",
      "  File \"/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "             │      └ <coroutine object InteractiveShell.run_cell_async at 0x10687da40>\n",
      "             └ <function _pseudo_sync_runner at 0x103e10cc0>\n",
      "  File \"/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "    │    └ <method 'send' of 'coroutine' objects>\n",
      "    └ <coroutine object InteractiveShell.run_cell_async at 0x10687da40>\n",
      "  File \"/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "                       │    │             │        │     └ '/var/folders/xs/kckld1vs7r714dlrd1t9llwr0000gn/T/ipykernel_89162/1898893634.py'\n",
      "                       │    │             │        └ [<ast.Import object at 0x137ba0a00>, <ast.Assign object at 0x137ba09a0>, <ast.For object at 0x137ba0880>]\n",
      "                       │    │             └ <ast.Module object at 0x137ba0a30>\n",
      "                       │    └ <function InteractiveShell.run_ast_nodes at 0x103e29e40>\n",
      "                       └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x1069ee210>\n",
      "  File \"/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "             │    │        │     │              └ False\n",
      "             │    │        │     └ <ExecutionResult object at 134387f50, execution_count=14 error_before_exec=None error_in_exec=None info=<ExecutionInfo object...\n",
      "             │    │        └ <code object <module> at 0x127e0a0d0, file \"/var/folders/xs/kckld1vs7r714dlrd1t9llwr0000gn/T/ipykernel_89162/1898893634.py\", ...\n",
      "             │    └ <function InteractiveShell.run_code at 0x103e29ee0>\n",
      "             └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x1069ee210>\n",
      "  File \"/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "         │         │    │               │    └ <unprintable dict object>\n",
      "         │         │    │               └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x1069ee210>\n",
      "         │         │    └ <property object at 0x103e249f0>\n",
      "         │         └ <ipykernel.zmqshell.ZMQInteractiveShell object at 0x1069ee210>\n",
      "         └ <code object <module> at 0x127e0a0d0, file \"/var/folders/xs/kckld1vs7r714dlrd1t9llwr0000gn/T/ipykernel_89162/1898893634.py\", ...\n",
      "\n",
      "  File \"\u001b[32m/var/folders/xs/kckld1vs7r714dlrd1t9llwr0000gn/T/ipykernel_89162/\u001b[0m\u001b[32m\u001b[1m1898893634.py\u001b[0m\", line \u001b[33m3\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    \u001b[35m\u001b[1mfor\u001b[0m \u001b[1mtoken\u001b[0m \u001b[35m\u001b[1min\u001b[0m \u001b[1mans\u001b[0m\u001b[1m:\u001b[0m\n",
      "    \u001b[36m             └ \u001b[0m\u001b[36m\u001b[1m<generator object BaseChain.stream at 0x127db3340>\u001b[0m\n",
      "\n",
      "> File \"\u001b[32m/Users/flybywindwen/Projects/llm-wechat/notebooks/../llmagent/chain/\u001b[0m\u001b[32m\u001b[1mbase.py\u001b[0m\", line \u001b[33m61\u001b[0m, in \u001b[35mstream\u001b[0m\n",
      "    \u001b[35m\u001b[1mfor\u001b[0m \u001b[1mtok\u001b[0m \u001b[35m\u001b[1min\u001b[0m \u001b[1mself\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1m_langchain\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1mstream\u001b[0m\u001b[1m(\u001b[0m\u001b[1mquestion\u001b[0m\u001b[1m)\u001b[0m\u001b[1m:\u001b[0m\n",
      "    \u001b[36m           │                      └ \u001b[0m\u001b[36m\u001b[1m'langchain提示词管理'\u001b[0m\n",
      "    \u001b[36m           └ \u001b[0m\u001b[36m\u001b[1m<unprintable QAWithContextChain object>\u001b[0m\n",
      "\n",
      "  File \"/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/langchain_core/runnables/base.py\", line 3407, in stream\n",
      "    yield from self.transform(iter([input]), config, **kwargs)\n",
      "               │    │               │        │         └ {}\n",
      "               │    │               │        └ None\n",
      "               │    │               └ 'langchain提示词管理'\n",
      "               │    └ <function RunnableSequence.transform at 0x111ac7600>\n",
      "               └ <unprintable RunnableSequence object>\n",
      "  File \"/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/langchain_core/runnables/base.py\", line 3394, in transform\n",
      "    yield from self._transform_stream_with_config(\n",
      "               │    └ <function Runnable._transform_stream_with_config at 0x111ac5e40>\n",
      "               └ <unprintable RunnableSequence object>\n",
      "  File \"/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/langchain_core/runnables/base.py\", line 2197, in _transform_stream_with_config\n",
      "    chunk: Output = context.run(next, iterator)  # type: ignore\n",
      "                    │       │         └ <generator object RunnableSequence._transform at 0x127d85bc0>\n",
      "                    │       └ <method 'run' of '_contextvars.Context' objects>\n",
      "                    └ <_contextvars.Context object at 0x13447c1c0>\n",
      "  File \"/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/langchain_core/runnables/base.py\", line 3357, in _transform\n",
      "    yield from final_pipeline\n",
      "               └ <generator object BaseTransformOutputParser.transform at 0x12733c340>\n",
      "  File \"/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/langchain_core/output_parsers/transform.py\", line 64, in transform\n",
      "    yield from self._transform_stream_with_config(\n",
      "               │    └ <function Runnable._transform_stream_with_config at 0x111ac5e40>\n",
      "               └ StrOutputParser()\n",
      "  File \"/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/langchain_core/runnables/base.py\", line 2161, in _transform_stream_with_config\n",
      "    final_input: Optional[Input] = next(input_for_tracing, None)\n",
      "                 │        │             └ <itertools._tee object at 0x1270b2380>\n",
      "                 │        └ -Input\n",
      "                 └ typing.Optional\n",
      "  File \"/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/langchain_core/runnables/base.py\", line 1431, in transform\n",
      "    yield from self.stream(final, config, **kwargs)\n",
      "               │    │      │      │         └ {}\n",
      "               │    │      │      └ {'tags': [], 'metadata': {}, 'callbacks': <langchain_core.callbacks.manager.CallbackManager object at 0x1343cbf50>, 'recursio...\n",
      "               │    │      └ [SystemMessage(content='你是一个解答用户问题的assistant，可以根据context资料回答问题。请尽量保证回答的内容都可以在context中找到根据，并务必保留资料最后的 source。以下是context资料：\\nTi...\n",
      "               │    └ <function QwenLLM.stream at 0x1270ace00>\n",
      "               └ QwenLLM(model_spec=QianFanModel(name='qwen-plus', max_str_len=131072, max_token_len=129024), top_p=0.5)\n",
      "\n",
      "  File \"\u001b[32m/Users/flybywindwen/Projects/llm-wechat/notebooks/../llmagent/llmapi/\u001b[0m\u001b[32m\u001b[1mllm.py\u001b[0m\", line \u001b[33m112\u001b[0m, in \u001b[35mstream\u001b[0m\n",
      "    \u001b[1mcompletion\u001b[0m \u001b[35m\u001b[1m=\u001b[0m \u001b[1mself\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1m_model\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1mchat\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1mcompletions\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1mcreate\u001b[0m\u001b[1m(\u001b[0m\u001b[1mmodel\u001b[0m\u001b[35m\u001b[1m=\u001b[0m\u001b[1mself\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1mmodel_spec\u001b[0m\u001b[35m\u001b[1m.\u001b[0m\u001b[1mname\u001b[0m\u001b[1m,\u001b[0m\n",
      "    \u001b[36m             │                                         │    │          └ \u001b[0m\u001b[36m\u001b[1m_tuplegetter(0, 'Alias for field number 0')\u001b[0m\n",
      "    \u001b[36m             │                                         │    └ \u001b[0m\u001b[36m\u001b[1mQianFanModel(name='qwen-plus', max_str_len=131072, max_token_len=129024)\u001b[0m\n",
      "    \u001b[36m             │                                         └ \u001b[0m\u001b[36m\u001b[1mQwenLLM(model_spec=QianFanModel(name='qwen-plus', max_str_len=131072, max_token_len=129024), top_p=0.5)\u001b[0m\n",
      "    \u001b[36m             └ \u001b[0m\u001b[36m\u001b[1mQwenLLM(model_spec=QianFanModel(name='qwen-plus', max_str_len=131072, max_token_len=129024), top_p=0.5)\u001b[0m\n",
      "\n",
      "  File \"/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           │     │       └ {'model': 'qwen-plus', 'messages': [SystemMessage(content='你是一个解答用户问题的assistant，可以根据context资料回答问题。请尽量保证回答的内容都可以在context中找到根据，...\n",
      "           │     └ (<openai.resources.chat.completions.Completions object at 0x13455a290>,)\n",
      "           └ <function Completions.create at 0x117f39260>\n",
      "  File \"/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 742, in create\n",
      "    return self._post(\n",
      "           │    └ <bound method SyncAPIClient.post of <openai.OpenAI object at 0x127c14f10>>\n",
      "           └ <openai.resources.chat.completions.Completions object at 0x13455a290>\n",
      "  File \"/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/openai/_base_client.py\", line 1277, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "           │    │          │    │       │        │            │                  └ openai.Stream[openai.types.chat.chat_completion_chunk.ChatCompletionChunk]\n",
      "           │    │          │    │       │        │            └ True\n",
      "           │    │          │    │       │        └ FinalRequestOptions(method='post', url='/chat/completions', params={}, headers=NOT_GIVEN, max_retries=NOT_GIVEN, timeout=NOT_...\n",
      "           │    │          │    │       └ <class 'openai.types.chat.chat_completion.ChatCompletion'>\n",
      "           │    │          │    └ <function SyncAPIClient.request at 0x114596200>\n",
      "           │    │          └ <openai.OpenAI object at 0x127c14f10>\n",
      "           │    └ ~ResponseT\n",
      "           └ <function cast at 0x100e06160>\n",
      "  File \"/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/openai/_base_client.py\", line 954, in request\n",
      "    return self._request(\n",
      "           │    └ <function SyncAPIClient._request at 0x1145962a0>\n",
      "           └ <openai.OpenAI object at 0x127c14f10>\n",
      "  File \"/Users/flybywindwen/miniconda3/envs/llm-wechat/lib/python3.11/site-packages/openai/_base_client.py\", line 1058, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "          │    └ <function BaseClient._make_status_error_from_response at 0x1145949a0>\n",
      "          └ <openai.OpenAI object at 0x127c14f10>\n",
      "\n",
      "\u001b[31m\u001b[1mopenai.BadRequestError\u001b[0m:\u001b[1m Error code: 400 - {'error': {'code': None, 'param': None, 'message': \"null is not one of ['system', 'assistant', 'user', 'tool', 'function'] - 'messages.['0].role'\", 'type': 'invalid_request_error'}}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "ans = prompt.stream(\"langchain提示词管理\")\n",
    "for token in ans:\n",
    "    for c in token:\n",
    "        time.sleep(0.1)\n",
    "        print(c, end=\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-10-24 09:12:30.621\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mllmagent.llmapi.llm\u001b[0m:\u001b[36m_stream\u001b[0m:\u001b[36m38\u001b[0m - \u001b[34m\u001b[1mPrompt: 你是一个解答用户问题的assistant，可以根据context资料回答问题。请尽量保证回答的内容都可以在context中找到根据，并务必保留资料最后的 source。以下是context资料：\n",
      "LangChain模块之 Callbacks (https://python.langchain.com/docs/modules/callbacks/)  回调模块允许接到LLM应用程序的各个阶段，鉴于LLM的幻觉问题，这对于日志记录、监视、流式处理和其他任务非常有用，现在也有专用的工具Helicone，Arize AI等产品可用，具体看 LLM应用生态初创公司说明 (../ref/company.md)  自定义回调对象  所有的回调对象都是基于这个基类来声明的  class  BaseCallbackHandler :  \"\"\"Base callback handler that\n",
      "source: https://aitutor.liduos.com/02-langchain/02-2-3.html\n",
      "\n",
      "LangChain模块之 Callbacks (https://python.langchain.com/docs/modules/callbacks/)  回调模块允许接到LLM应用程序的各个阶段，鉴于LLM的幻觉问题，这对于日志记录、监视、流式处理和其他任务非常有用，现在也有专用的工具Helicone，Arize AI等产品可用，具体看 LLM应用生态初创公司说明 (../ref/company.md)  自定义回调对象  所有的回调对象都是基于这个基类来声明的  class  BaseCallbackHandler :  \"\"\"Base callback handler that\n",
      "source: https://aitutor.liduos.com/02-langchain/02-2-3.html\n",
      "\n",
      "LangChain模块之 Callbacks (https://python.langchain.com/docs/modules/callbacks/)  回调模块允许接到LLM应用程序的各个阶段，鉴于LLM的幻觉问题，这对于日志记录、监视、流式处理和其他任务非常有用，现在也有专用的工具Helicone，Arize AI等产品可用，具体看 LLM应用生态初创公司说明 (../ref/company.md)  自定义回调对象  所有的回调对象都是基于这个基类来声明的  class  BaseCallbackHandler :  \"\"\"Base callback handler that\n",
      "source: https://aitutor.liduos.com/02-langchain/02-2-3.html\n",
      "\n",
      "LangChain模块之 Chains (https://python.langchain.com/docs/modules/chains/)  链定义为对组件的一系列调用，也可以包括其他链，这种在链中将组件组合在一起的想法很简单但功能强大，极大地简化了复杂应用程序的实现并使其更加模块化，这反过来又使调试、维护和改进应用程序变得更加容易。 Chain基类是所有chain对象的基本入口，与用户程序交互，处理用户的输入，准备其他模块的输入，提供内存能力，chain的回调能力，其他所有的 Chain 类都继承自这个基类，并根据需要实现特定的功能。  class  Chain\n",
      "source: https://aitutor.liduos.com/02-langchain/02-2-1.html\n",
      "\n",
      "LangChain模块之 Chains (https://python.langchain.com/docs/modules/chains/)  链定义为对组件的一系列调用，也可以包括其他链，这种在链中将组件组合在一起的想法很简单但功能强大，极大地简化了复杂应用程序的实现并使其更加模块化，这反过来又使调试、维护和改进应用程序变得更加容易。 Chain基类是所有chain对象的基本入口，与用户程序交互，处理用户的输入，准备其他模块的输入，提供内存能力，chain的回调能力，其他所有的 Chain 类都继承自这个基类，并根据需要实现特定的功能。  class  Chain\n",
      "source: https://aitutor.liduos.com/02-langchain/02-2-1.html\n",
      "\n",
      "LangChain模块之 Chains (https://python.langchain.com/docs/modules/chains/)  链定义为对组件的一系列调用，也可以包括其他链，这种在链中将组件组合在一起的想法很简单但功能强大，极大地简化了复杂应用程序的实现并使其更加模块化，这反过来又使调试、维护和改进应用程序变得更加容易。 Chain基类是所有chain对象的基本入口，与用户程序交互，处理用户的输入，准备其他模块的输入，提供内存能力，chain的回调能力，其他所有的 Chain 类都继承自这个基类，并根据需要实现特定的功能。  class  Chain\n",
      "source: https://aitutor.liduos.com/02-langchain/02-2-1.html\n",
      "\n",
      "Title    LangChain之Callback模块 (..)         本电子书开源，欢迎 star 🌟，关注《LLM 应用开发实践笔记》  我的新书 《LangChain编程从入门到实践》 (https://u.jd.com/V8pkqFY) 已经开售！推荐正在学习AI应用开发的朋友购买阅读！   LangChain模块之 Callbacks (https://python.langchain.com/docs/modules/callbacks/)\n",
      "source: https://aitutor.liduos.com/02-langchain/02-2-3.html\n",
      "\n",
      "Title    LangChain之Callback模块 (..)         本电子书开源，欢迎 star 🌟，关注《LLM 应用开发实践笔记》  我的新书 《LangChain编程从入门到实践》 (https://u.jd.com/V8pkqFY) 已经开售！推荐正在学习AI应用开发的朋友购买阅读！   LangChain模块之 Callbacks (https://python.langchain.com/docs/modules/callbacks/)\n",
      "source: https://aitutor.liduos.com/02-langchain/02-2-3.html\n",
      "\n",
      "Title    LangChain之Callback模块 (..)         本电子书开源，欢迎 star 🌟，关注《LLM 应用开发实践笔记》  我的新书 《LangChain编程从入门到实践》 (https://u.jd.com/V8pkqFY) 已经开售！推荐正在学习AI应用开发的朋友购买阅读！   LangChain模块之 Callbacks (https://python.langchain.com/docs/modules/callbacks/)\n",
      "source: https://aitutor.liduos.com/02-langchain/02-2-3.html\n",
      "\n",
      "Title    LangChain模块学习 (..)         本电子书开源，欢迎 star 🌟，关注《LLM 应用开发实践笔记》  我的新书 《LangChain编程从入门到实践》 (https://u.jd.com/V8pkqFY) 已经开售！推荐正在学习AI应用开发的朋友购买阅读！   LangChain模块解读  LangChain 分为 6 个模块，分别是对（大语言）模型输入输出的管理、外部数据接入、 链的概念 (02-2-1.html) 、（上下文记忆）存储管理、智能代理以及回调系统，通过文档的组织结构，你可以清晰了解到\n",
      "source: https://aitutor.liduos.com/02-langchain/02-2.html，\n",
      "以下是之前的聊天历史：\n",
      "human: langchain提示词管理\n",
      "ai: langchain提示词管理是指在使用大型语言模型（LLM）进行应用开发时，对于提供给模型的输入文本（即提示词）的管理。提示词是引导大型语言模型生成特定主题或类型文本的关键。在langchain框架中，提示词管理是一个重要的部分，它涉及到提示词的编排、日志监控、测试及分析等工作。具体来说，langchain提示词管理可能包括以下几个方面：\n",
      "\n",
      "1. 提示词编排：根据需求，将提示词进行组织、归类和格式化，以便更好地引导模型生成所需的输出。2. 日志监控：对提示词的使用情况进行监控，以便了解哪些提示词更有效，哪些可能需要调整。3. 测试与分析：通过测试不同的提示词，分析它们对模型输出的影响，从而优化提示词的效果。在langchain中，提示词管理与模型服务层通过API相关联，这有助于更高效地与大型语言模型进行交互。参考资料：\n",
      "\n",
      "* https://aitutor.liduos.com/06-llmops/06-3.html\n",
      "* https://aitutor.liduos.com/02-langchain/02-2-1.html\n",
      "\n",
      "希望以上内容对你有帮助，更多关于langchain提示词管理的信息，建议咨询相关领域的专业人士或查阅langchain官方文档。\n",
      "问题：langchain回调管理器如何使用\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING][2024-10-24 09:12:30.622] base.py:916 [t:8703163072]: This key `disable_search` does not seem to be a parameter that the model `ERNIE-Speed-128K` will accept\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在LangChain中，回调管理器是一个非常有用的模块，它允许开发者在大型语言模型（LLM）应用程序的各个阶段插入自定义回调函数，以实现日志记录、监视、流式处理等其他任务。为了使用LangChain的回调管理器，你可以遵循以下步骤：\n",
      "\n",
      "1. 自定义回调对象：所有的回调对象都是基于`BaseCallbackHandler`这个基类来声明的。你可以根据自己的需求继承这个基类并实现特定的功能。2. 注册回调：在LangChain应用程序中，你需要将自定义的回调对象注册到回调管理器中。这样，当应用程序的特定阶段触发时，相应的回调函数就会被调用。3. 实现回调函数：在自定义的回调对象中，你需要实现具体的回调函数。这些函数将根据应用程序的阶段和事件进行触发，并执行相应的任务，如日志记录、数据监视等。4. 配置和使用：根据LangChain的文档和示例，配置回调管理器的使用。这可能涉及到在配置文件中指定回调对象的参数，或者在代码中直接实例化并配置回调对象。请注意，由于LangChain是一个不断发展和迭代的框架，具体的API和使用方式可能会有所变化。为了获得最准确和最新的信息，建议查阅LangChain的官方文档、参考示例代码或咨询相关领域的专业人士。此外，对于大型语言模型（LLM）的幻觉问题，回调管理器也可以用于日志记录和监视，以帮助识别和减少模型的幻觉。这也是使用LangChain回调管理器的一个重要应用场景。希望以上信息对你有所帮助！如果你还有其他问题，欢迎继续提问。"
     ]
    }
   ],
   "source": [
    "ans = prompt.stream(\"langchain回调管理器如何使用\")\n",
    "for token in ans:\n",
    "    for c in token:\n",
    "        time.sleep(0.03)\n",
    "        print(c, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt.conf.history_num=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='langchain回调管理器如何使用', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='在LangChain中，回调管理器是一个非常有用的模块，它允许开发者在大型语言模型（LLM）应用程序的各个阶段插入自定义回调函数，以实现日志记录、监视、流式处理等其他任务。为了使用LangChain的回调管理器，你可以遵循以下步骤：\\n\\n1. 自定义回调对象：所有的回调对象都是基于`BaseCallbackHandler`这个基类来声明的。你可以根据自己的需求继承这个基类并实现特定的功能。2. 注册回调：在LangChain应用程序中，你需要将自定义的回调对象注册到回调管理器中。这样，当应用程序的特定阶段触发时，相应的回调函数就会被调用。3. 实现回调函数：在自定义的回调对象中，你需要实现具体的回调函数。这些函数将根据应用程序的阶段和事件进行触发，并执行相应的任务，如日志记录、数据监视等。4. 配置和使用：根据LangChain的文档和示例，配置回调管理器的使用。这可能涉及到在配置文件中指定回调对象的参数，或者在代码中直接实例化并配置回调对象。请注意，由于LangChain是一个不断发展和迭代的框架，具体的API和使用方式可能会有所变化。为了获得最准确和最新的信息，建议查阅LangChain的官方文档、参考示例代码或咨询相关领域的专业人士。此外，对于大型语言模型（LLM）的幻觉问题，回调管理器也可以用于日志记录和监视，以帮助识别和减少模型的幻觉。这也是使用LangChain回调管理器的一个重要应用场景。希望以上信息对你有所帮助！如果你还有其他问题，欢迎继续提问。', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt._get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-10-24 09:13:24.433\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mllmagent.llmapi.llm\u001b[0m:\u001b[36m_stream\u001b[0m:\u001b[36m38\u001b[0m - \u001b[34m\u001b[1mPrompt: 你是一个解答用户问题的assistant，可以根据context资料回答问题。请尽量保证回答的内容都可以在context中找到根据，并务必保留资料最后的 source。以下是context资料：\n",
      "the ChatGPT API》教程面向想要基于 LLM 开发应用程序的开发者，简洁有效而又系统全面地介绍了如何基于 ChatGPT API 打造完整的对话系统；《LangChain for LLM Application Development》教程结合经典大模型开源框架 LangChain，介绍了如何基于 LangChain 框架开发具备实用功能、能力全面的应用程序，《LangChain Chat With Your Data》教程则在此基础上进一步介绍了如何使用 LangChain 架构结合个人私有数据开发个性化大模型应用；《Building Generative AI\n",
      "source: https://aitutor.liduos.com/ref/ref.html\n",
      "\n",
      "the ChatGPT API》教程面向想要基于 LLM 开发应用程序的开发者，简洁有效而又系统全面地介绍了如何基于 ChatGPT API 打造完整的对话系统；《LangChain for LLM Application Development》教程结合经典大模型开源框架 LangChain，介绍了如何基于 LangChain 框架开发具备实用功能、能力全面的应用程序，《LangChain Chat With Your Data》教程则在此基础上进一步介绍了如何使用 LangChain 架构结合个人私有数据开发个性化大模型应用；《Building Generative AI\n",
      "source: https://aitutor.liduos.com/ref/ref.html\n",
      "\n",
      "the ChatGPT API》教程面向想要基于 LLM 开发应用程序的开发者，简洁有效而又系统全面地介绍了如何基于 ChatGPT API 打造完整的对话系统；《LangChain for LLM Application Development》教程结合经典大模型开源框架 LangChain，介绍了如何基于 LangChain 框架开发具备实用功能、能力全面的应用程序，《LangChain Chat With Your Data》教程则在此基础上进一步介绍了如何使用 LangChain 架构结合个人私有数据开发个性化大模型应用；《Building Generative AI\n",
      "source: https://aitutor.liduos.com/ref/ref.html\n",
      "\n",
      "API、LangChain 架构快速开发结合大模型强大能力的应用。其中，《Prompt Engineering for Developers》教程面向入门 LLM 的开发者，深入浅出地介绍了对于开发者，如何构造 Prompt 并基于 OpenAI 提供的 API 实现包括总结、推断、转换等多种常用功能，是入门 LLM 开发的经典教程；《Building Systems with the ChatGPT API》教程面向想要基于 LLM 开发应用程序的开发者，简洁有效而又系统全面地介绍了如何基于 ChatGPT API 打造完整的对话系统；《LangChain for LLM\n",
      "source: https://aitutor.liduos.com/ref/ref.html\n",
      "\n",
      "API、LangChain 架构快速开发结合大模型强大能力的应用。其中，《Prompt Engineering for Developers》教程面向入门 LLM 的开发者，深入浅出地介绍了对于开发者，如何构造 Prompt 并基于 OpenAI 提供的 API 实现包括总结、推断、转换等多种常用功能，是入门 LLM 开发的经典教程；《Building Systems with the ChatGPT API》教程面向想要基于 LLM 开发应用程序的开发者，简洁有效而又系统全面地介绍了如何基于 ChatGPT API 打造完整的对话系统；《LangChain for LLM\n",
      "source: https://aitutor.liduos.com/ref/ref.html\n",
      "\n",
      "API、LangChain 架构快速开发结合大模型强大能力的应用。其中，《Prompt Engineering for Developers》教程面向入门 LLM 的开发者，深入浅出地介绍了对于开发者，如何构造 Prompt 并基于 OpenAI 提供的 API 实现包括总结、推断、转换等多种常用功能，是入门 LLM 开发的经典教程；《Building Systems with the ChatGPT API》教程面向想要基于 LLM 开发应用程序的开发者，简洁有效而又系统全面地介绍了如何基于 ChatGPT API 打造完整的对话系统；《LangChain for LLM\n",
      "source: https://aitutor.liduos.com/ref/ref.html\n",
      "\n",
      "Title    LangChain之Callback模块 (..)         本电子书开源，欢迎 star 🌟，关注《LLM 应用开发实践笔记》  我的新书 《LangChain编程从入门到实践》 (https://u.jd.com/V8pkqFY) 已经开售！推荐正在学习AI应用开发的朋友购买阅读！   LangChain模块之 Callbacks (https://python.langchain.com/docs/modules/callbacks/)\n",
      "source: https://aitutor.liduos.com/02-langchain/02-2-3.html\n",
      "\n",
      "Title    LangChain之Callback模块 (..)         本电子书开源，欢迎 star 🌟，关注《LLM 应用开发实践笔记》  我的新书 《LangChain编程从入门到实践》 (https://u.jd.com/V8pkqFY) 已经开售！推荐正在学习AI应用开发的朋友购买阅读！   LangChain模块之 Callbacks (https://python.langchain.com/docs/modules/callbacks/)\n",
      "source: https://aitutor.liduos.com/02-langchain/02-2-3.html\n",
      "\n",
      "Title    LangChain之Callback模块 (..)         本电子书开源，欢迎 star 🌟，关注《LLM 应用开发实践笔记》  我的新书 《LangChain编程从入门到实践》 (https://u.jd.com/V8pkqFY) 已经开售！推荐正在学习AI应用开发的朋友购买阅读！   LangChain模块之 Callbacks (https://python.langchain.com/docs/modules/callbacks/)\n",
      "source: https://aitutor.liduos.com/02-langchain/02-2-3.html\n",
      "\n",
      "Chain 类可能用于处理文本数据，有些可能用于处理图像数据，有些可能用于处理音频数据等。  从 LangChainHub 加载链  LangChainHub (https://github.com/hwchase17/langchain-hub) 托管了一些高质量Prompt、Agent和Chain，可以直接在langchain中使用。  def  test_mathchain () :  from langchain.chains import load_chain chain = load_chain( \"lc://chains/llm-math/chain.json\" ) \"\"\" >\n",
      "source: https://aitutor.liduos.com/02-langchain/02-2-1.html，\n",
      "以下是之前的聊天历史：\n",
      "human: langchain回调管理器如何使用\n",
      "ai: 在LangChain中，回调管理器是一个非常有用的模块，它允许开发者在大型语言模型（LLM）应用程序的各个阶段插入自定义回调函数，以实现日志记录、监视、流式处理等其他任务。为了使用LangChain的回调管理器，你可以遵循以下步骤：\n",
      "\n",
      "1. 自定义回调对象：所有的回调对象都是基于`BaseCallbackHandler`这个基类来声明的。你可以根据自己的需求继承这个基类并实现特定的功能。2. 注册回调：在LangChain应用程序中，你需要将自定义的回调对象注册到回调管理器中。这样，当应用程序的特定阶段触发时，相应的回调函数就会被调用。3. 实现回调函数：在自定义的回调对象中，你需要实现具体的回调函数。这些函数将根据应用程序的阶段和事件进行触发，并执行相应的任务，如日志记录、数据监视等。4. 配置和使用：根据LangChain的文档和示例，配置回调管理器的使用。这可能涉及到在配置文件中指定回调对象的参数，或者在代码中直接实例化并配置回调对象。请注意，由于LangChain是一个不断发展和迭代的框架，具体的API和使用方式可能会有所变化。为了获得最准确和最新的信息，建议查阅LangChain的官方文档、参考示例代码或咨询相关领域的专业人士。此外，对于大型语言模型（LLM）的幻觉问题，回调管理器也可以用于日志记录和监视，以帮助识别和减少模型的幻觉。这也是使用LangChain回调管理器的一个重要应用场景。希望以上信息对你有所帮助！如果你还有其他问题，欢迎继续提问。\n",
      "问题：除了langchain，还有哪些ChatGPT框架\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING][2024-10-24 09:13:24.434] base.py:916 [t:8703163072]: This key `disable_search` does not seem to be a parameter that the model `ERNIE-Speed-128K` will accept\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "除了LangChain，还有以下几个ChatGPT框架：\n",
      "\n",
      "1. OpenAI的GPT-3框架：这是目前最流行的ChatGPT框架之一，由OpenAI开发和维护，提供各种基于AI的对话系统的能力，API可以进行即席试用和探索式迁移。开发人员可灵活地按需重建查询系统和下一代逻辑应用。GPT-3框架具有强大的自然语言处理能力，可实现高效的对话系统构建。2. Hugging Face的Transformers库：这是一个广泛使用的自然语言处理库，提供了许多预训练的语言模型，包括ChatGPT模型。Transformers库支持多种语言和任务，并且有丰富的文档和示例代码，方便开发者使用。Transformers库还提供了丰富的工具和功能，帮助开发者构建高效的对话系统。请注意，这些框架的使用方法各不相同。如果需要详细了解其特点和使用方式，请访问相关的官方网站获取最新的技术信息和支持文档。这些技术也在不断演进和更新中，因此建议查阅最新的官方文档或咨询专业人士以获取最新信息。"
     ]
    }
   ],
   "source": [
    "ans = prompt.stream(\"除了langchain，还有哪些ChatGPT框架\")\n",
    "for token in ans:\n",
    "    for c in token:\n",
    "        time.sleep(0.03)\n",
    "        print(c, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'langchain回调管理器如何使用\\n除了langchain，还有哪些ChatGPT框架'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.get_history_wo_role()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-wechat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
